{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from style_encoder import StyleEncoder\n",
    "from content_encoder import ContentEncoder\n",
    "from discriminator import Discriminator\n",
    "from decoder import Decoder\n",
    "from losses import (infoNCE_loss, margin_loss, adversarial_loss, \n",
    "                   disentanglement_loss, compute_comprehensive_loss)\n",
    "from Dataloader import get_dataloader\n",
    "\n",
    "# Configurazione dei dispositivi\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1. Parametri di configurazione\n",
    "# ==============================\n",
    "config = {\n",
    "    # Architettura\n",
    "    \"style_dim\": 256,\n",
    "    \"content_dim\": 256,\n",
    "    \"transformer_heads\": 4,\n",
    "    \"transformer_layers\": 4,\n",
    "    \"cnn_channels\": [16, 32, 64, 128, 256],\n",
    "    \n",
    "    # Training\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 16,  # Deve essere pari per bilanciare piano/violino\n",
    "    \"lr\": 2e-4,\n",
    "    \"beta1\": 0.5,\n",
    "    \"beta2\": 0.999,\n",
    "    \n",
    "    # Pesi delle loss\n",
    "    \"lambda_adv_disc\": 1.0,     # Discriminatore\n",
    "    \"lambda_adv_gen\": 0.1,      # Generatore (entropia)\n",
    "    \"lambda_disent\": 0.5,       # Disaccoppiamento stile-contenuto\n",
    "    \"lambda_cont\": 0.5,         # Loss contrastiva (InfoNCE)\n",
    "    \"lambda_margin\": 0.2,       # Margin loss\n",
    "    \"lambda_recon\": 10.0,       # Ricostruzione\n",
    "    \n",
    "    # Percorsi dati\n",
    "    \"piano_dir\": \"path/to/piano_dataset\",\n",
    "    \"violin_dir\": \"path/to/violin_dataset\",\n",
    "    \"stats_path\": \"stats_stft_cqt.npz\",\n",
    "    \n",
    "    # Salvataggio\n",
    "    \"save_dir\": \"checkpoints\",\n",
    "    \"save_interval\": 5,\n",
    "}\n",
    "\n",
    "# Creazione directory salvataggio\n",
    "os.makedirs(config[\"save_dir\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inizializzazione modelli\n",
    "style_encoder = StyleEncoder(\n",
    "    cnn_out_dim=config[\"style_dim\"],\n",
    "    transformer_dim=config[\"style_dim\"],\n",
    "    num_heads=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"],\n",
    "    channels_list=config[\"cnn_channels\"]\n",
    ").to(device)\n",
    "\n",
    "content_encoder = ContentEncoder(\n",
    "    cnn_out_dim=config[\"content_dim\"],\n",
    "    transformer_dim=config[\"content_dim\"],\n",
    "    num_heads=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"],\n",
    "    channels_list=config[\"cnn_channels\"]\n",
    ").to(device)\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    input_dim=config[\"style_dim\"],\n",
    "    hidden_dim=128\n",
    ").to(device)\n",
    "\n",
    "decoder = Decoder(\n",
    "    d_model=config[\"style_dim\"],\n",
    "    nhead=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"]\n",
    ").to(device)\n",
    "\n",
    "# Inizializzazione pesi\n",
    "def init_weights(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "style_encoder.apply(init_weights)\n",
    "content_encoder.apply(init_weights)\n",
    "discriminator.apply(init_weights)\n",
    "decoder.apply(init_weights)\n",
    "\n",
    "# 3. Ottimizzatori\n",
    "# =================\n",
    "# Ottimizzatori separati per gruppi di modelli\n",
    "optimizer_G = optim.Adam(\n",
    "    list(style_encoder.parameters()) + \n",
    "    list(content_encoder.parameters()) + \n",
    "    list(decoder.parameters()),\n",
    "    lr=config[\"lr\"],\n",
    "    betas=(config[\"beta1\"], config[\"beta2\"])\n",
    ")\n",
    "\n",
    "optimizer_D = optim.Adam(\n",
    "    discriminator.parameters(),\n",
    "    lr=config[\"lr\"],\n",
    "    betas=(config[\"beta1\"], config[\"beta2\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Dataset e DataLoader\n",
    "# ========================\n",
    "\n",
    "\n",
    "train_loader = get_dataloader(\n",
    "    piano_dir=config[\"piano_dir\"],\n",
    "    violin_dir=config[\"violin_dir\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    stats_path=config[\"stats_path\"]\n",
    ")\n",
    "\n",
    "# 5. Funzioni di utilità\n",
    "# =======================\n",
    "def set_requires_grad(models, requires_grad):\n",
    "    \"\"\"Abilita/disabilita i gradienti per un insieme di modelli\"\"\"\n",
    "    if not isinstance(models, list):\n",
    "        models = [models]\n",
    "    for model in models:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "def save_checkpoint(epoch):\n",
    "    \"\"\"Salva i checkpoint dei modelli\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'style_encoder': style_encoder.state_dict(),\n",
    "        'content_encoder': content_encoder.state_dict(),\n",
    "        'discriminator': discriminator.state_dict(),\n",
    "        'decoder': decoder.state_dict(),\n",
    "        'optimizer_G': optimizer_G.state_dict(),\n",
    "        'optimizer_D': optimizer_D.state_dict(),\n",
    "        'config': config\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(config[\"save_dir\"], f\"checkpoint_epoch_{epoch}.pth\"))\n",
    "\n",
    "# 6. Ciclo di training\n",
    "# =====================\n",
    "# Struttura per tenere traccia delle loss\n",
    "loss_history = {\n",
    "    'total_G': [],\n",
    "    'disc': [],\n",
    "    'disent': [],\n",
    "    'cont': [],\n",
    "    'margin': [],\n",
    "    'recon': [],\n",
    "    'adv_gen': []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc7647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(config[\"epochs\"]), desc=\"Training Progress\"):\n",
    "    # Modalità training per tutti i modelli\n",
    "    style_encoder.train()\n",
    "    content_encoder.train()\n",
    "    discriminator.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "        x = x.to(device)          # (B, S, 2, T, F)\n",
    "        labels = labels.to(device) # (B,)\n",
    "        \n",
    "        # ==================================================================\n",
    "        # Fase 1: Aggiornamento del Discriminatore\n",
    "        # ==================================================================\n",
    "        set_requires_grad([style_encoder, content_encoder, decoder], False)\n",
    "        set_requires_grad(discriminator, True)\n",
    "        \n",
    "        # Forward pass encoders\n",
    "        with torch.no_grad():\n",
    "            style_emb, class_emb = style_encoder(x, labels)\n",
    "            content_emb = content_encoder(x)\n",
    "        \n",
    "        # Calcolo loss adversarial per il discriminatore\n",
    "        disc_loss, _ = adversarial_loss(\n",
    "            style_emb.detach(),\n",
    "            class_emb.detach(),\n",
    "            content_emb.detach(),\n",
    "            discriminator,\n",
    "            labels,\n",
    "            compute_for_discriminator=True,\n",
    "            lambda_content=config[\"lambda_adv_disc\"]\n",
    "        )\n",
    "        \n",
    "        # Backpropagazione e aggiornamento\n",
    "        optimizer_D.zero_grad()\n",
    "        disc_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # ==================================================================\n",
    "        # Fase 2: Aggiornamento dei Generator (Encoders + Decoder)\n",
    "        # ==================================================================\n",
    "        set_requires_grad([style_encoder, content_encoder, decoder], True)\n",
    "        set_requires_grad(discriminator, False)\n",
    "        \n",
    "        # Forward pass encoders\n",
    "        style_emb, class_emb = style_encoder(x, labels)\n",
    "        content_emb = content_encoder(x)\n",
    "        \n",
    "        # Calcolo loss adversarial per il generatore\n",
    "        _, adv_gen_loss = adversarial_loss(\n",
    "            style_emb,\n",
    "            class_emb,\n",
    "            content_emb,\n",
    "            discriminator,\n",
    "            labels,\n",
    "            compute_for_discriminator=False,\n",
    "            lambda_content=config[\"lambda_adv_gen\"]\n",
    "        )\n",
    "        \n",
    "        # Loss di disaccoppiamento stile-contenuto\n",
    "        disent_loss = disentanglement_loss(\n",
    "            style_emb,\n",
    "            content_emb.mean(dim=1),  # Media lungo la sequenza\n",
    "            use_hsic=True\n",
    "        )\n",
    "        \n",
    "        # Loss contrastive\n",
    "        cont_loss = infoNCE_loss(style_emb, labels)\n",
    "        \n",
    "        # Margin loss per class embeddings\n",
    "        margin_loss_val = margin_loss(class_emb)\n",
    "        \n",
    "        # Ricostruzione audio\n",
    "        recon_x = decoder(content_emb, class_emb, y=x)\n",
    "        recon_losses = compute_comprehensive_loss(recon_x, x)\n",
    "        recon_loss = recon_losses['total_loss']\n",
    "        \n",
    "        # Loss totale per il generatore\n",
    "        total_G_loss = (\n",
    "            config[\"lambda_adv_gen\"] * adv_gen_loss +\n",
    "            config[\"lambda_disent\"] * disent_loss +\n",
    "            config[\"lambda_cont\"] * cont_loss +\n",
    "            config[\"lambda_margin\"] * margin_loss_val +\n",
    "            config[\"lambda_recon\"] * recon_loss\n",
    "        )\n",
    "        \n",
    "        # Backpropagazione e aggiornamento\n",
    "        optimizer_G.zero_grad()\n",
    "        total_G_loss.backward()\n",
    "        \n",
    "        # Gradient clipping per stabilizzare il training\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            list(style_encoder.parameters()) + \n",
    "            list(content_encoder.parameters()) +\n",
    "            list(decoder.parameters()),\n",
    "            1.0\n",
    "        )\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Registrazione delle loss\n",
    "        loss_history['disc'].append(disc_loss.item())\n",
    "        loss_history['disent'].append(disent_loss.item())\n",
    "        loss_history['cont'].append(cont_loss.item())\n",
    "        loss_history['margin'].append(margin_loss_val.item())\n",
    "        loss_history['recon'].append(recon_loss.item())\n",
    "        loss_history['adv_gen'].append(adv_gen_loss.item())\n",
    "        loss_history['total_G'].append(total_G_loss.item())\n",
    "    \n",
    "    # ==================================================================\n",
    "    # Operazioni di fine epoca\n",
    "    # ==================================================================\n",
    "    # Salvataggio checkpoint\n",
    "    if (epoch + 1) % config[\"save_interval\"] == 0:\n",
    "        save_checkpoint(epoch + 1)\n",
    "    \n",
    "    # Logging delle loss medie\n",
    "    avg_losses = {k: np.mean(v[-len(train_loader):]) for k, v in loss_history.items()}\n",
    "    print(f\"\\nEpoch {epoch+1}/{config['epochs']}:\")\n",
    "    print(f\"  Disc Loss: {avg_losses['disc']:.4f}\")\n",
    "    print(f\"  Total G Loss: {avg_losses['total_G']:.4f}\")\n",
    "    print(f\"  Recon Loss: {avg_losses['recon']:.4f}\")\n",
    "    print(f\"  Disent Loss: {avg_losses['disent']:.4f}\")\n",
    "\n",
    "# 7. Salvataggio finale e visualizzazione\n",
    "# ========================================\n",
    "save_checkpoint(config[\"epochs\"])\n",
    "\n",
    "# Plot delle loss\n",
    "plt.figure(figsize=(12, 8))\n",
    "for loss_name, values in loss_history.items():\n",
    "    plt.plot(values, label=loss_name)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(config[\"save_dir\"], \"loss_curves.png\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
