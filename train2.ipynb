{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b3761a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from style_encoder import StyleEncoder\n",
    "from content_encoder import ContentEncoder\n",
    "from discriminator import Discriminator\n",
    "from new_decoder import Decoder, compute_comprehensive_loss\n",
    "from losses import (infoNCE_loss, margin_loss, adversarial_loss, \n",
    "                   disentanglement_loss)\n",
    "from Dataloader import get_dataloader\n",
    "\n",
    "# Configurazione dei dispositivi\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed54964",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Architettura\n",
    "    \"style_dim\": 256,\n",
    "    \"content_dim\": 256,\n",
    "    \"transformer_heads\": 4,\n",
    "    \"transformer_layers\": 4,\n",
    "    \"cnn_channels\": [16, 32, 64, 128, 256],\n",
    "    \n",
    "    # Training\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"beta1\": 0.5,\n",
    "    \"beta2\": 0.999,\n",
    "    \n",
    "    # Pesi delle loss\n",
    "    \"lambda_adv_disc\": 1.0,\n",
    "    \"lambda_adv_gen\": 0.1,\n",
    "    \"lambda_disent\": 0.5,\n",
    "    \"lambda_cont\": 0.5,\n",
    "    \"lambda_margin\": 0.2,\n",
    "    \"lambda_recon\": 10.0,\n",
    "    \n",
    "    # Percorsi dati\n",
    "    \"piano_dir\": \"dataset/train/piano\",\n",
    "    \"violin_dir\": \"dataset/train/violin\",\n",
    "    \"stats_path\": \"stats_stft_cqt.npz\",\n",
    "    \n",
    "    # Salvataggio\n",
    "    \"save_dir\": \"checkpoints\",\n",
    "    \"save_interval\": 5,\n",
    "    \n",
    "    # Training strategy\n",
    "    \"discriminator_steps\": 1,  # Numero di step discriminator per step generator\n",
    "    \"generator_steps\": 1,      # Numero di step generator per step discriminator\n",
    "}\n",
    "\n",
    "# Creazione directory salvataggio\n",
    "os.makedirs(config[\"save_dir\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cffa1bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (conv_encoder): Sequential(\n",
       "    (0): Conv2d(2, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): AdaptiveAvgPool2d(output_size=(32, 16))\n",
       "  )\n",
       "  (spatial_projection): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (feature_to_sequence): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (sequence_to_feature): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (conv_decoder): Sequential(\n",
       "    (0): ConvTranspose2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (10): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): ConvTranspose2d(8, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): Upsample(size=(287, 513), mode='bilinear')\n",
       "  )\n",
       "  (content_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (class_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (pos_encoding): SinusoidalPositionalEncoding()\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_encoder = StyleEncoder(\n",
    "    cnn_out_dim=config[\"style_dim\"],\n",
    "    transformer_dim=config[\"style_dim\"],\n",
    "    num_heads=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"]\n",
    ").to(device)\n",
    "\n",
    "content_encoder = ContentEncoder(\n",
    "    cnn_out_dim=config[\"content_dim\"],\n",
    "    transformer_dim=config[\"content_dim\"],\n",
    "    num_heads=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"],\n",
    "    channels_list=config[\"cnn_channels\"]\n",
    ").to(device)\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    input_dim=config[\"style_dim\"],\n",
    "    hidden_dim=128\n",
    ").to(device)\n",
    "\n",
    "decoder = Decoder(\n",
    "    d_model=config[\"style_dim\"],\n",
    "    nhead=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"]\n",
    ").to(device)\n",
    "\n",
    "# Inizializzazione pesi\n",
    "def init_weights(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "style_encoder.apply(init_weights)\n",
    "content_encoder.apply(init_weights)\n",
    "discriminator.apply(init_weights)\n",
    "decoder.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "265f5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Ottimizzatori\n",
    "# =================\n",
    "# Ottimizzatori separati per gruppi di modelli\n",
    "optimizer_G = optim.Adam(\n",
    "    list(style_encoder.parameters()) + \n",
    "    list(content_encoder.parameters()) + \n",
    "    list(decoder.parameters()),\n",
    "    lr=config[\"lr\"],\n",
    "    betas=(config[\"beta1\"], config[\"beta2\"])\n",
    ")\n",
    "\n",
    "optimizer_D = optim.Adam(\n",
    "    discriminator.parameters(),\n",
    "    lr=config[\"lr\"],\n",
    "    betas=(config[\"beta1\"], config[\"beta2\"])\n",
    ")\n",
    "\n",
    "train_loader = get_dataloader(\n",
    "    piano_dir=config[\"piano_dir\"],\n",
    "    violin_dir=config[\"violin_dir\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    stats_path=config[\"stats_path\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbc144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_requires_grad(models, requires_grad):\n",
    "    \"\"\"Abilita/disabilita i gradienti per un insieme di modelli\"\"\"\n",
    "    if not isinstance(models, list):\n",
    "        models = [models]\n",
    "    for model in models:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "def save_checkpoint(epoch):\n",
    "    \"\"\"Salva i checkpoint dei modelli\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'style_encoder': style_encoder.state_dict(),\n",
    "        'content_encoder': content_encoder.state_dict(),\n",
    "        'discriminator': discriminator.state_dict(),\n",
    "        'decoder': decoder.state_dict(),\n",
    "        'optimizer_G': optimizer_G.state_dict(),\n",
    "        'optimizer_D': optimizer_D.state_dict(),\n",
    "        'config': config\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(config[\"save_dir\"], f\"checkpoint_epoch_{epoch}.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ee512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_training_step(x, labels):\n",
    "    \"\"\"Singolo step di training per il discriminatore\"\"\"\n",
    "    \n",
    "    # only discriminator gets gradients\n",
    "    set_requires_grad(discriminator, True)\n",
    "    set_requires_grad([style_encoder, content_encoder, decoder], False)\n",
    "    \n",
    "    # no gradient flow for generators\n",
    "    with torch.no_grad():\n",
    "        style_emb, class_emb = style_encoder(x, labels)\n",
    "        content_emb = content_encoder(x)\n",
    "        \n",
    "        # Debug: controlla se ci sono NaN negli embeddings\n",
    "    if torch.isnan(style_emb).any() or torch.isnan(class_emb).any() or torch.isnan(content_emb).any():\n",
    "        print(\"WARNING: NaN detected in embeddings!\")\n",
    "        print(f\"style_emb has NaN: {torch.isnan(style_emb).any()}\")\n",
    "        print(f\"class_emb has NaN: {torch.isnan(class_emb).any()}\")\n",
    "        print(f\"content_emb has NaN: {torch.isnan(content_emb).any()}\")\n",
    "        return float('nan')\n",
    "    \n",
    "    # compute loss with detach\n",
    "    disc_loss, _ = adversarial_loss(\n",
    "        style_emb.detach(), \n",
    "        class_emb.detach(),\n",
    "        content_emb.detach(),\n",
    "        discriminator,\n",
    "        labels,\n",
    "        compute_for_discriminator=True,\n",
    "        lambda_content=config[\"lambda_adv_disc\"]\n",
    "    )\n",
    "    \n",
    "        # Debug: controlla se la loss è NaN\n",
    "    if torch.isnan(disc_loss):\n",
    "        print(\"WARNING: NaN in discriminator loss!\")\n",
    "        return float('nan')\n",
    "    \n",
    "    # discriminator backprop\n",
    "    optimizer_D.zero_grad()\n",
    "    disc_loss.backward()\n",
    "    \n",
    "    # Gradient clipping per il discriminatore\n",
    "    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 1.0)\n",
    "    \n",
    "    optimizer_D.step()\n",
    "    \n",
    "    return disc_loss.item()\n",
    "\n",
    "\n",
    "\n",
    "def generator_training_step(x, labels):\n",
    "    \"\"\"Singolo step di training per i generatori\"\"\"\n",
    "\n",
    "    set_requires_grad([style_encoder, content_encoder, decoder], True)\n",
    "    set_requires_grad(discriminator, False)\n",
    "    \n",
    "\n",
    "    style_emb, class_emb = style_encoder(x, labels)\n",
    "    content_emb = content_encoder(x)\n",
    "    \n",
    "    if torch.isnan(style_emb).any() or torch.isnan(class_emb).any() or torch.isnan(content_emb).any():\n",
    "        print(\"WARNING: NaN detected in generator embeddings!\")\n",
    "        return {\n",
    "            'total_G': float('nan'),\n",
    "            'adv_gen': float('nan'),\n",
    "            'disent': float('nan'),\n",
    "            'cont': float('nan'),\n",
    "            'margin': float('nan'),\n",
    "            'recon': float('nan')\n",
    "        }\n",
    "    \n",
    "    # keep grads\n",
    "    _, adv_gen_loss = adversarial_loss(\n",
    "        style_emb, \n",
    "        class_emb,\n",
    "        content_emb,\n",
    "        discriminator,\n",
    "        labels,\n",
    "        compute_for_discriminator=False,\n",
    "        lambda_content=config[\"lambda_adv_gen\"]\n",
    "    )\n",
    "    \n",
    "    # disentanglement loss\n",
    "    disent_loss = disentanglement_loss(\n",
    "        style_emb,\n",
    "        content_emb.mean(dim=1),\n",
    "        use_hsic=True\n",
    "    )\n",
    "    \n",
    "    # contrastive loss\n",
    "    cont_loss = infoNCE_loss(style_emb, labels)\n",
    "    \n",
    "    # margin loss \n",
    "    margin_loss_val = margin_loss(class_emb)\n",
    "    \n",
    "    # reconstruction loss\n",
    "    stft_part = x[:, :, :, :, :513]\n",
    "    recon_x = decoder(content_emb, style_emb, y=stft_part)\n",
    "    recon_losses = compute_comprehensive_loss(recon_x, stft_part)\n",
    "    recon_loss = recon_losses['total_loss']\n",
    "    \n",
    "    \n",
    "    # Debug: controlla se qualche loss è NaN\n",
    "    losses_to_check = [adv_gen_loss, disent_loss, cont_loss, margin_loss_val, recon_loss]\n",
    "    loss_names = ['adv_gen', 'disent', 'cont', 'margin', 'recon']\n",
    "    \n",
    "    for loss_val, loss_name in zip(losses_to_check, loss_names):\n",
    "        if torch.isnan(loss_val):\n",
    "            print(f\"WARNING: NaN in {loss_name} loss!\")\n",
    "            \n",
    "    \n",
    "    total_G_loss = (\n",
    "        config[\"lambda_adv_gen\"] * adv_gen_loss +\n",
    "        config[\"lambda_disent\"] * disent_loss +\n",
    "        config[\"lambda_cont\"] * cont_loss +\n",
    "        config[\"lambda_margin\"] * margin_loss_val +\n",
    "        config[\"lambda_recon\"] * recon_loss\n",
    "    )\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer_G.zero_grad()\n",
    "    total_G_loss.backward()\n",
    "    \n",
    "    # Gradient clipping\n",
    "    torch.nn.utils.clip_grad_norm_(\n",
    "        list(style_encoder.parameters()) + \n",
    "        list(content_encoder.parameters()) +\n",
    "        list(decoder.parameters()),\n",
    "        0.5\n",
    "    )\n",
    "    \n",
    "    optimizer_G.step()\n",
    "    \n",
    "    return {\n",
    "        'total_G': total_G_loss.item(),\n",
    "        'adv_gen': adv_gen_loss.item(),\n",
    "        'disent': disent_loss.item(),\n",
    "        'cont': cont_loss.item(),\n",
    "        'margin': margin_loss_val.item(),\n",
    "        'recon': recon_loss.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc7647d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0:\n",
      "  D_loss: 1.6904 | G_total: 29.2459\n",
      "  Recon: 2.8032 | Disent: 0.0020 | Cont: 2.5507\n",
      "  Margin: 0.0000 | Adv_gen: -0.6212\n",
      "----------------------------------------\n",
      "WARNING: NaN detected in embeddings!\n",
      "style_emb has NaN: True\n",
      "class_emb has NaN: True\n",
      "content_emb has NaN: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 1/100 [00:41<1:08:32, 41.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: NaN detected in generator embeddings!\n",
      "Epoch 1, Batch 1: NaN detected in discriminator loss!\n",
      "\n",
      "Epoch 1/100 Summary:\n",
      "  disc: nan\n",
      "  total_G: nan\n",
      "  recon: nan\n",
      "  disent: nan\n",
      "  cont: nan\n",
      "  margin: nan\n",
      "--------------------------------------------------\n",
      "WARNING: NaN detected in embeddings!\n",
      "style_emb has NaN: True\n",
      "class_emb has NaN: True\n",
      "content_emb has NaN: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 2/100 [00:51<37:46, 23.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: NaN detected in generator embeddings!\n",
      "Epoch 2, Batch 0: NaN detected in discriminator loss!\n",
      "\n",
      "Epoch 2/100 Summary:\n",
      "  disc: nan\n",
      "  total_G: nan\n",
      "  recon: nan\n",
      "  disent: nan\n",
      "  cont: nan\n",
      "  margin: nan\n",
      "--------------------------------------------------\n",
      "WARNING: NaN detected in embeddings!\n",
      "style_emb has NaN: True\n",
      "class_emb has NaN: True\n",
      "content_emb has NaN: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 3/100 [01:02<27:56, 17.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: NaN detected in generator embeddings!\n",
      "Epoch 3, Batch 0: NaN detected in discriminator loss!\n",
      "\n",
      "Epoch 3/100 Summary:\n",
      "  disc: nan\n",
      "  total_G: nan\n",
      "  recon: nan\n",
      "  disent: nan\n",
      "  cont: nan\n",
      "  margin: nan\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 3/100 [01:05<35:32, 21.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# ================================================================\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Alternating training: Discriminator -> Generator\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# ================================================================\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Step 1: Train Discriminator\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscriminator_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m---> 33\u001b[0m     disc_loss \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator_training_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     epoch_losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(disc_loss)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Step 2: Train Generator\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mdiscriminator_training_step\u001b[0;34m(x, labels)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# no gradient flow for generators\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 10\u001b[0m     style_emb, class_emb \u001b[38;5;241m=\u001b[39m \u001b[43mstyle_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     content_emb \u001b[38;5;241m=\u001b[39m content_encoder(x)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Debug: controlla se ci sono NaN negli embeddings\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/Audio-Style-Transfer/style_encoder.py:207\u001b[0m, in \u001b[0;36mStyleEncoder.forward\u001b[0;34m(self, x, labels)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Merge batch and sections\u001b[39;00m\n\u001b[1;32m    206\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(B \u001b[38;5;241m*\u001b[39m S, C, T, F)                              \u001b[38;5;66;03m# (B*S, 2, T, F)\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m cnn_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m                              \u001b[38;5;66;03m# (B*S, cnn_out_dim)\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Reshape sequence to (B, S, cnn_out_dim)\u001b[39;00m\n\u001b[1;32m    209\u001b[0m seq \u001b[38;5;241m=\u001b[39m cnn_features\u001b[38;5;241m.\u001b[39mview(B, S, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)                       \u001b[38;5;66;03m# (B, S, cnn_out_dim)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/Audio-Style-Transfer/style_encoder.py:125\u001b[0m, in \u001b[0;36mDeepCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# x shape: (B*S, 2, T, F)\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m                                         \u001b[38;5;66;03m# (B*S, last_chan_size, 1, 1)\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)                               \u001b[38;5;66;03m# (B*S, last_chan_size)\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x)                                        \u001b[38;5;66;03m# (B*S, out_dim)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/Audio-Style-Transfer/style_encoder.py:80\u001b[0m, in \u001b[0;36mResBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     79\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n\u001b[0;32m---> 80\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     82\u001b[0m     out \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU()(out)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 6. Ciclo di training principale\n",
    "# ================================\n",
    "loss_history = {\n",
    "    'total_G': [],\n",
    "    'disc': [],\n",
    "    'disent': [],\n",
    "    'cont': [],\n",
    "    'margin': [],\n",
    "    'recon': [],\n",
    "    'adv_gen': []\n",
    "}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in tqdm(range(config[\"epochs\"]), desc=\"Training Progress\"):\n",
    "    # Modalità training per tutti i modelli\n",
    "    style_encoder.train()\n",
    "    content_encoder.train()\n",
    "    discriminator.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    epoch_losses = {key: [] for key in loss_history.keys()}\n",
    "    \n",
    "    for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "        x = x.to(device)          # (B, S, 2, T, F)\n",
    "        labels = labels.to(device) # (B,)\n",
    "        \n",
    "        # ================================================================\n",
    "        # Alternating training: Discriminator -> Generator\n",
    "        # ================================================================\n",
    "        \n",
    "        # Step 1: Train Discriminator\n",
    "        for _ in range(config[\"discriminator_steps\"]):\n",
    "            disc_loss = discriminator_training_step(x, labels)\n",
    "            epoch_losses['disc'].append(disc_loss)\n",
    "        \n",
    "        # Step 2: Train Generator\n",
    "        for _ in range(config[\"generator_steps\"]):\n",
    "            gen_losses = generator_training_step(x, labels)\n",
    "            \n",
    "            # Aggiungi tutte le loss del generatore\n",
    "            for key, value in gen_losses.items():\n",
    "                epoch_losses[key].append(value)\n",
    "        \n",
    "        # Log progress periodically\n",
    "        if batch_idx % 1 == 0:\n",
    "            \n",
    "            # Controlla se ci sono NaN nelle loss prima di calcolare le medie\n",
    "            if any(np.isnan(epoch_losses['disc'][-config[\"discriminator_steps\"]:])):\n",
    "                print(f\"Epoch {epoch+1}, Batch {batch_idx}: NaN detected in discriminator loss!\")\n",
    "                break\n",
    "            if any(np.isnan(epoch_losses['total_G'][-config[\"generator_steps\"]:])):\n",
    "                print(f\"Epoch {epoch+1}, Batch {batch_idx}: NaN detected in generator loss!\")\n",
    "                break\n",
    "            \n",
    "            \n",
    "            avg_disc = np.mean(epoch_losses['disc'][-config[\"discriminator_steps\"]:])\n",
    "            avg_gen = np.mean(epoch_losses['total_G'][-config[\"generator_steps\"]:])\n",
    "            avg_recon = np.mean(epoch_losses['recon'][-config[\"generator_steps\"]:])\n",
    "            avg_disent = np.mean(epoch_losses['disent'][-config[\"generator_steps\"]:])\n",
    "            avg_cont = np.mean(epoch_losses['cont'][-config[\"generator_steps\"]:])\n",
    "            avg_margin = np.mean(epoch_losses['margin'][-config[\"generator_steps\"]:])\n",
    "            avg_adv_gen = np.mean(epoch_losses['adv_gen'][-config[\"generator_steps\"]:])\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx}:\")\n",
    "            print(f\"  D_loss: {avg_disc:.4f} | G_total: {avg_gen:.4f}\")\n",
    "            print(f\"  Recon: {avg_recon:.4f} | Disent: {avg_disent:.4f} | Cont: {avg_cont:.4f}\")\n",
    "            print(f\"  Margin: {avg_margin:.4f} | Adv_gen: {avg_adv_gen:.4f}\")\n",
    "            print(\"-\" * 40)\n",
    "    \n",
    "    # ================================================================\n",
    "    # Fine epoca: salvataggio e logging\n",
    "    # ================================================================\n",
    "    \n",
    "    # Aggiungi loss dell'epoca alla storia\n",
    "    for key in loss_history.keys():\n",
    "        if epoch_losses[key]:  # Solo se ci sono valori\n",
    "            loss_history[key].extend(epoch_losses[key])\n",
    "    \n",
    "    # Salvataggio checkpoint\n",
    "    if (epoch + 1) % config[\"save_interval\"] == 0:\n",
    "        save_checkpoint(epoch + 1)\n",
    "    \n",
    "    # Logging delle loss medie dell'epoca\n",
    "    print(f\"\\nEpoch {epoch+1}/{config['epochs']} Summary:\")\n",
    "    for key in ['disc', 'total_G', 'recon', 'disent', 'cont', 'margin']:\n",
    "        if epoch_losses[key]:\n",
    "            avg_loss = np.mean(epoch_losses[key])\n",
    "            print(f\"  {key}: {avg_loss:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 7. Salvataggio finale e visualizzazione\n",
    "# ========================================\n",
    "save_checkpoint(config[\"epochs\"])\n",
    "\n",
    "# Plot delle loss\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Crea subplot per diverse categorie di loss\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "loss_groups = [\n",
    "    ('disc', 'Discriminator Loss'),\n",
    "    ('total_G', 'Generator Total Loss'),\n",
    "    ('recon', 'Reconstruction Loss'),\n",
    "    ('disent', 'Disentanglement Loss'),\n",
    "    ('cont', 'Contrastive Loss'),\n",
    "    ('adv_gen', 'Adversarial Generator Loss')\n",
    "]\n",
    "\n",
    "for i, (loss_name, title) in enumerate(loss_groups):\n",
    "    if loss_name in loss_history and loss_history[loss_name]:\n",
    "        # Smooth the curves for better visualization\n",
    "        values = loss_history[loss_name]\n",
    "        if len(values) > 100:\n",
    "            # Moving average for smoother curves\n",
    "            window = len(values) // 100\n",
    "            smoothed = np.convolve(values, np.ones(window)/window, mode='valid')\n",
    "            axes[i].plot(smoothed, label=f'{loss_name} (smoothed)')\n",
    "        axes[i].plot(values, alpha=0.3, label=f'{loss_name} (raw)')\n",
    "        axes[i].set_title(title)\n",
    "        axes[i].set_xlabel('Iteration')\n",
    "        axes[i].set_ylabel('Loss')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config[\"save_dir\"], \"loss_curves.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "669fc2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "✅ DataLoader created successfully with batch_size=8\n",
      "🚀 Starting enhanced training with NaN protection...\n",
      "📊 Configuration: {'style_dim': 128, 'content_dim': 128, 'transformer_heads': 2, 'transformer_layers': 2, 'cnn_channels': [16, 32, 64, 128], 'epochs': 100, 'batch_size': 8, 'lr': 1e-05, 'beta1': 0.5, 'beta2': 0.999, 'weight_decay': 1e-06, 'lambda_adv_disc': 0.5, 'lambda_adv_gen': 0.1, 'lambda_disent': 0.1, 'lambda_cont': 0.1, 'lambda_margin': 0.05, 'lambda_recon': 1.0, 'grad_clip_value': 0.25, 'grad_accumulation_steps': 2, 'warmup_epochs': 5, 'nan_check_interval': 10, 'early_stop_nan_count': 5, 'piano_dir': 'dataset/train/piano', 'violin_dir': 'dataset/train/violin', 'stats_path': 'stats_stft_cqt.npz', 'save_dir': 'checkpoints', 'save_interval': 10, 'discriminator_steps': 1, 'generator_steps': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 Epoch 1/100, Batch 0\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 2.6985\n",
      "   recon: 2.6641\n",
      "\n",
      "📈 Epoch 1/100, Batch 1\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 3.7735\n",
      "   recon: 3.7391\n",
      "\n",
      "📈 Epoch 1/100, Batch 2\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 4.8772\n",
      "   recon: 4.8430\n",
      "\n",
      "📈 Epoch 1/100, Batch 3\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 3.1949\n",
      "   recon: 3.1606\n",
      "\n",
      "📈 Epoch 1/100, Batch 4\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 3.1626\n",
      "   recon: 3.1284\n",
      "\n",
      "📈 Epoch 1/100, Batch 5\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 4.5419\n",
      "   recon: 4.5078\n",
      "\n",
      "📈 Epoch 1/100, Batch 6\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 2.8154\n",
      "   recon: 2.7818\n",
      "\n",
      "📈 Epoch 1/100, Batch 7\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 2.3858\n",
      "   recon: 2.3520\n",
      "\n",
      "📈 Epoch 1/100, Batch 8\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 3.6728\n",
      "   recon: 3.6392\n",
      "\n",
      "📈 Epoch 1/100, Batch 9\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 3.8458\n",
      "   recon: 3.8122\n",
      "\n",
      "📈 Epoch 1/100, Batch 10\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 3.9670\n",
      "   recon: 3.9333\n",
      "\n",
      "📈 Epoch 1/100, Batch 11\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 2.7972\n",
      "   recon: 2.7640\n",
      "\n",
      "📈 Epoch 1/100, Batch 12\n",
      "   NaN count: 0\n",
      "   disc: 1.3863\n",
      "   total_G: 3.0790\n",
      "   recon: 3.0458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [03:28<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏹️  Training interrupted by user\n",
      "💾 Checkpoint saved: checkpoints/checkpoint_epoch_1.pth\n",
      "\n",
      "🎯 Training session completed!\n",
      "   Total NaN occurrences: 0\n",
      "   Checkpoints saved in: checkpoints\n",
      "   Final learning rates - G: [1e-05], D: [1e-05]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from style_encoder import StyleEncoder\n",
    "from content_encoder import ContentEncoder\n",
    "from discriminator import Discriminator\n",
    "from new_decoder import Decoder, compute_comprehensive_loss\n",
    "from losses import (infoNCE_loss, margin_loss, adversarial_loss, \n",
    "                   disentanglement_loss)\n",
    "from Dataloader import get_dataloader\n",
    "\n",
    "# Enhanced device configuration with memory management\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
    "    print(f\"Memory reserved: {torch.cuda.memory_reserved()/1024**2:.2f} MB\")\n",
    "\n",
    "# Enhanced configuration with more conservative settings\n",
    "config = {\n",
    "    # Architecture - reduced complexity\n",
    "    \"style_dim\": 128,  # Reduced from 256\n",
    "    \"content_dim\": 128,  # Reduced from 256\n",
    "    \"transformer_heads\": 2,  # Reduced from 4\n",
    "    \"transformer_layers\": 2,  # Reduced from 4\n",
    "    \"cnn_channels\": [16, 32, 64, 128],  # Reduced depth\n",
    "    \n",
    "    # Training - very conservative settings\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 8,  # Reduced from 16\n",
    "    \"lr\": 1e-5,  # Much more conservative\n",
    "    \"beta1\": 0.5,\n",
    "    \"beta2\": 0.999,\n",
    "    \"weight_decay\": 1e-6,  # Added weight decay\n",
    "    \n",
    "    # Loss weights - more balanced\n",
    "    \"lambda_adv_disc\": 0.5,  # Reduced\n",
    "    \"lambda_adv_gen\": 0.1,\n",
    "    \"lambda_disent\": 0.1,    # Reduced\n",
    "    \"lambda_cont\": 0.1,      # Reduced\n",
    "    \"lambda_margin\": 0.05,   # Reduced\n",
    "    \"lambda_recon\": 1.0,     # Reduced significantly\n",
    "    \n",
    "    # Gradient control\n",
    "    \"grad_clip_value\": 0.25,  # Very conservative\n",
    "    \"grad_accumulation_steps\": 2,  # Accumulate gradients\n",
    "    \n",
    "    # Stability controls\n",
    "    \"warmup_epochs\": 5,\n",
    "    \"nan_check_interval\": 10,\n",
    "    \"early_stop_nan_count\": 5,\n",
    "    \n",
    "    # Paths\n",
    "    \"piano_dir\": \"dataset/train/piano\",\n",
    "    \"violin_dir\": \"dataset/train/violin\",\n",
    "    \"stats_path\": \"stats_stft_cqt.npz\",\n",
    "    \n",
    "    # Saving\n",
    "    \"save_dir\": \"checkpoints\",\n",
    "    \"save_interval\": 10,\n",
    "    \n",
    "    # Training strategy\n",
    "    \"discriminator_steps\": 1,\n",
    "    \"generator_steps\": 1,\n",
    "}\n",
    "\n",
    "# Create save directory\n",
    "os.makedirs(config[\"save_dir\"], exist_ok=True)\n",
    "\n",
    "# Enhanced weight initialization\n",
    "def init_weights_conservative(m):\n",
    "    \"\"\"More conservative weight initialization to prevent NaN\"\"\"\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        # Xavier initialization for conv layers\n",
    "        nn.init.xavier_uniform_(m.weight, gain=0.1)  # Small gain\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        # Xavier initialization for linear layers\n",
    "        nn.init.xavier_uniform_(m.weight, gain=0.1)  # Small gain\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.MultiheadAttention):\n",
    "        # Special handling for transformer attention\n",
    "        if hasattr(m, 'in_proj_weight') and m.in_proj_weight is not None:\n",
    "            nn.init.xavier_uniform_(m.in_proj_weight, gain=0.1)\n",
    "        if hasattr(m, 'out_proj') and m.out_proj.weight is not None:\n",
    "            nn.init.xavier_uniform_(m.out_proj.weight, gain=0.1)\n",
    "\n",
    "# NaN detection and handling utilities\n",
    "class NaNDetector:\n",
    "    def __init__(self):\n",
    "        self.nan_count = 0\n",
    "        self.max_nan_count = config[\"early_stop_nan_count\"]\n",
    "    \n",
    "    def check_tensor(self, tensor, name=\"tensor\"):\n",
    "        \"\"\"Check if tensor contains NaN or Inf\"\"\"\n",
    "        if torch.isnan(tensor).any():\n",
    "            print(f\"⚠️  NaN detected in {name}!\")\n",
    "            self.nan_count += 1\n",
    "            return True\n",
    "        if torch.isinf(tensor).any():\n",
    "            print(f\"⚠️  Inf detected in {name}!\")\n",
    "            self.nan_count += 1\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def check_model_parameters(self, model, model_name):\n",
    "        \"\"\"Check all model parameters for NaN/Inf\"\"\"\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                if self.check_tensor(param.grad, f\"{model_name}.{name}.grad\"):\n",
    "                    return True\n",
    "            if self.check_tensor(param, f\"{model_name}.{name}\"):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def should_stop(self):\n",
    "        return self.nan_count >= self.max_nan_count\n",
    "\n",
    "# Initialize models with conservative settings\n",
    "style_encoder = StyleEncoder(\n",
    "    cnn_out_dim=config[\"style_dim\"],\n",
    "    transformer_dim=config[\"style_dim\"],\n",
    "    num_heads=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"]\n",
    ").to(device)\n",
    "\n",
    "content_encoder = ContentEncoder(\n",
    "    cnn_out_dim=config[\"content_dim\"],\n",
    "    transformer_dim=config[\"content_dim\"],\n",
    "    num_heads=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"],\n",
    "    channels_list=config[\"cnn_channels\"]\n",
    ").to(device)\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    input_dim=config[\"style_dim\"],\n",
    "    hidden_dim=64  # Reduced from 128\n",
    ").to(device)\n",
    "\n",
    "decoder = Decoder(\n",
    "    d_model=config[\"style_dim\"],\n",
    "    nhead=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"]\n",
    ").to(device)\n",
    "\n",
    "# Apply conservative initialization\n",
    "for model in [style_encoder, content_encoder, discriminator, decoder]:\n",
    "    model.apply(init_weights_conservative)\n",
    "\n",
    "# Initialize NaN detector\n",
    "nan_detector = NaNDetector()\n",
    "\n",
    "# Enhanced optimizers with weight decay\n",
    "optimizer_G = optim.AdamW(  # Using AdamW for better stability\n",
    "    list(style_encoder.parameters()) + \n",
    "    list(content_encoder.parameters()) + \n",
    "    list(decoder.parameters()),\n",
    "    lr=config[\"lr\"],\n",
    "    betas=(config[\"beta1\"], config[\"beta2\"]),\n",
    "    weight_decay=config[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "optimizer_D = optim.AdamW(\n",
    "    discriminator.parameters(),\n",
    "    lr=config[\"lr\"],\n",
    "    betas=(config[\"beta1\"], config[\"beta2\"]),\n",
    "    weight_decay=config[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "# Learning rate schedulers for stability\n",
    "scheduler_G = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_G, mode='min', factor=0.5, patience=5\n",
    ")\n",
    "\n",
    "scheduler_D = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_D, mode='min', factor=0.5, patience=5\n",
    ")\n",
    "\n",
    "# Dataset and DataLoader\n",
    "try:\n",
    "    train_loader = get_dataloader(\n",
    "        piano_dir=config[\"piano_dir\"],\n",
    "        violin_dir=config[\"violin_dir\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        stats_path=config[\"stats_path\"]\n",
    "    )\n",
    "    print(f\"✅ DataLoader created successfully with batch_size={config['batch_size']}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating DataLoader: {e}\")\n",
    "    raise\n",
    "\n",
    "# Enhanced utility functions\n",
    "def set_requires_grad(models, requires_grad):\n",
    "    \"\"\"Enable/disable gradients for models\"\"\"\n",
    "    if not isinstance(models, list):\n",
    "        models = [models]\n",
    "    for model in models:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "def save_checkpoint(epoch, additional_info=None):\n",
    "    \"\"\"Save model checkpoints with additional info\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'style_encoder': style_encoder.state_dict(),\n",
    "        'content_encoder': content_encoder.state_dict(),\n",
    "        'discriminator': discriminator.state_dict(),\n",
    "        'decoder': decoder.state_dict(),\n",
    "        'optimizer_G': optimizer_G.state_dict(),\n",
    "        'optimizer_D': optimizer_D.state_dict(),\n",
    "        'scheduler_G': scheduler_G.state_dict(),\n",
    "        'scheduler_D': scheduler_D.state_dict(),\n",
    "        'config': config,\n",
    "        'nan_count': nan_detector.nan_count\n",
    "    }\n",
    "    \n",
    "    if additional_info:\n",
    "        checkpoint.update(additional_info)\n",
    "    \n",
    "    checkpoint_path = os.path.join(config[\"save_dir\"], f\"checkpoint_epoch_{epoch}.pth\")\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"💾 Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "def get_learning_rate_multiplier(epoch):\n",
    "    \"\"\"Get learning rate multiplier for warmup\"\"\"\n",
    "    if epoch < config[\"warmup_epochs\"]:\n",
    "        return (epoch + 1) / config[\"warmup_epochs\"]\n",
    "    return 1.0\n",
    "\n",
    "def safe_loss_computation(loss_fn, *args, **kwargs):\n",
    "    \"\"\"Safely compute loss with NaN checking\"\"\"\n",
    "    try:\n",
    "        loss = loss_fn(*args, **kwargs)\n",
    "        if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
    "            print(f\"⚠️  Invalid loss detected in {loss_fn.__name__}\")\n",
    "            return torch.tensor(0.0, device=device, requires_grad=True)\n",
    "        return loss\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in loss computation {loss_fn.__name__}: {e}\")\n",
    "        return torch.tensor(0.0, device=device, requires_grad=True)\n",
    "\n",
    "def discriminator_training_step(x, labels, epoch):\n",
    "    \"\"\"Enhanced discriminator training step with NaN protection\"\"\"\n",
    "    set_requires_grad(discriminator, True)\n",
    "    set_requires_grad([style_encoder, content_encoder, decoder], False)\n",
    "    \n",
    "    # Forward pass with gradient stopping\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            style_emb, class_emb = style_encoder(x, labels)\n",
    "            content_emb = content_encoder(x)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in encoder forward pass: {e}\")\n",
    "            return float('nan')\n",
    "    \n",
    "    # Check for NaN in embeddings\n",
    "    if (nan_detector.check_tensor(style_emb, \"style_emb\") or \n",
    "        nan_detector.check_tensor(class_emb, \"class_emb\") or \n",
    "        nan_detector.check_tensor(content_emb, \"content_emb\")):\n",
    "        return float('nan')\n",
    "    \n",
    "    # Compute discriminator loss\n",
    "    try:\n",
    "        disc_loss, _ = adversarial_loss(\n",
    "            style_emb.detach(),\n",
    "            class_emb.detach(),\n",
    "            content_emb.detach(),\n",
    "            discriminator,\n",
    "            labels,\n",
    "            compute_for_discriminator=True,\n",
    "            lambda_content=config[\"lambda_adv_disc\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in discriminator loss computation: {e}\")\n",
    "        return float('nan')\n",
    "    \n",
    "    if nan_detector.check_tensor(disc_loss, \"disc_loss\"):\n",
    "        return float('nan')\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer_D.zero_grad()\n",
    "    disc_loss.backward()\n",
    "    \n",
    "    # Gradient clipping\n",
    "    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), config[\"grad_clip_value\"])\n",
    "    \n",
    "    # Check gradients\n",
    "    if nan_detector.check_model_parameters(discriminator, \"discriminator\"):\n",
    "        return float('nan')\n",
    "    \n",
    "    optimizer_D.step()\n",
    "    \n",
    "    return disc_loss.item()\n",
    "\n",
    "def generator_training_step(x, labels, epoch):\n",
    "    \"\"\"Enhanced generator training step with NaN protection\"\"\"\n",
    "    set_requires_grad([style_encoder, content_encoder, decoder], True)\n",
    "    set_requires_grad(discriminator, False)\n",
    "    \n",
    "    # Forward pass\n",
    "    try:\n",
    "        style_emb, class_emb = style_encoder(x, labels)\n",
    "        content_emb = content_encoder(x)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in generator forward pass: {e}\")\n",
    "        return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "    \n",
    "    # Check embeddings\n",
    "    if (nan_detector.check_tensor(style_emb, \"style_emb\") or \n",
    "        nan_detector.check_tensor(class_emb, \"class_emb\") or \n",
    "        nan_detector.check_tensor(content_emb, \"content_emb\")):\n",
    "        return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "    \n",
    "    # Compute losses safely\n",
    "    losses = {}\n",
    "    \n",
    "    # Adversarial loss for generator\n",
    "    try:\n",
    "        _, adv_gen_loss = adversarial_loss(\n",
    "            style_emb,\n",
    "            class_emb,\n",
    "            content_emb,\n",
    "            discriminator,\n",
    "            labels,\n",
    "            compute_for_discriminator=False,\n",
    "            lambda_content=config[\"lambda_adv_gen\"]\n",
    "        )\n",
    "        losses['adv_gen'] = adv_gen_loss\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in adversarial loss: {e}\")\n",
    "        losses['adv_gen'] = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "    \n",
    "    # Disentanglement loss\n",
    "    try:\n",
    "        disent_loss = disentanglement_loss(\n",
    "            style_emb,\n",
    "            content_emb.mean(dim=1),\n",
    "            use_hsic=True\n",
    "        )\n",
    "        losses['disent'] = disent_loss\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in disentanglement loss: {e}\")\n",
    "        losses['disent'] = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "    \n",
    "    # Contrastive loss\n",
    "    try:\n",
    "        cont_loss = infoNCE_loss(style_emb, labels)\n",
    "        losses['cont'] = cont_loss\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in contrastive loss: {e}\")\n",
    "        losses['cont'] = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "    \n",
    "    # Margin loss\n",
    "    try:\n",
    "        margin_loss_val = margin_loss(class_emb)\n",
    "        losses['margin'] = margin_loss_val\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in margin loss: {e}\")\n",
    "        losses['margin'] = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "    \n",
    "    # Reconstruction loss\n",
    "    try:\n",
    "        stft_part = x[:, :, :, :, :513]\n",
    "        recon_x = decoder(content_emb, style_emb, y=stft_part)\n",
    "        recon_losses = compute_comprehensive_loss(recon_x, stft_part)\n",
    "        recon_loss = recon_losses['total_loss']\n",
    "        losses['recon'] = recon_loss\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in reconstruction loss: {e}\")\n",
    "        losses['recon'] = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "    \n",
    "    # Check all losses for NaN\n",
    "    for loss_name, loss_val in losses.items():\n",
    "        if nan_detector.check_tensor(loss_val, f\"{loss_name}_loss\"):\n",
    "            return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "    \n",
    "    # Apply learning rate warmup\n",
    "    lr_multiplier = get_learning_rate_multiplier(epoch)\n",
    "    \n",
    "    # Compute total loss with reduced weights during warmup\n",
    "    warmup_factor = lr_multiplier if epoch < config[\"warmup_epochs\"] else 1.0\n",
    "    \n",
    "    total_G_loss = (\n",
    "        config[\"lambda_adv_gen\"] * losses['adv_gen'] * warmup_factor +\n",
    "        config[\"lambda_disent\"] * losses['disent'] * warmup_factor +\n",
    "        config[\"lambda_cont\"] * losses['cont'] * warmup_factor +\n",
    "        config[\"lambda_margin\"] * losses['margin'] * warmup_factor +\n",
    "        config[\"lambda_recon\"] * losses['recon']\n",
    "    )\n",
    "    \n",
    "    if nan_detector.check_tensor(total_G_loss, \"total_G_loss\"):\n",
    "        return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer_G.zero_grad()\n",
    "    total_G_loss.backward()\n",
    "    \n",
    "    # Gradient clipping\n",
    "    torch.nn.utils.clip_grad_norm_(\n",
    "        list(style_encoder.parameters()) + \n",
    "        list(content_encoder.parameters()) +\n",
    "        list(decoder.parameters()),\n",
    "        config[\"grad_clip_value\"]\n",
    "    )\n",
    "    \n",
    "    # Check gradients\n",
    "    for model, name in [(style_encoder, \"style_encoder\"), \n",
    "                       (content_encoder, \"content_encoder\"), \n",
    "                       (decoder, \"decoder\")]:\n",
    "        if nan_detector.check_model_parameters(model, name):\n",
    "            return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "    \n",
    "    optimizer_G.step()\n",
    "    \n",
    "    return {\n",
    "        'total_G': total_G_loss.item(),\n",
    "        'adv_gen': losses['adv_gen'].item(),\n",
    "        'disent': losses['disent'].item(),\n",
    "        'cont': losses['cont'].item(),\n",
    "        'margin': losses['margin'].item(),\n",
    "        'recon': losses['recon'].item()\n",
    "    }\n",
    "\n",
    "# Training loop with enhanced monitoring\n",
    "loss_history = {\n",
    "    'total_G': [],\n",
    "    'disc': [],\n",
    "    'disent': [],\n",
    "    'cont': [],\n",
    "    'margin': [],\n",
    "    'recon': [],\n",
    "    'adv_gen': []\n",
    "}\n",
    "\n",
    "print(\"🚀 Starting enhanced training with NaN protection...\")\n",
    "print(f\"📊 Configuration: {config}\")\n",
    "\n",
    "try:\n",
    "    for epoch in tqdm(range(config[\"epochs\"]), desc=\"Training Progress\"):\n",
    "        if nan_detector.should_stop():\n",
    "            print(f\"🛑 Early stopping due to too many NaN occurrences ({nan_detector.nan_count})\")\n",
    "            break\n",
    "        \n",
    "        # Set models to training mode\n",
    "        for model in [style_encoder, content_encoder, discriminator, decoder]:\n",
    "            model.train()\n",
    "        \n",
    "        epoch_losses = {key: [] for key in loss_history.keys()}\n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            if nan_detector.should_stop():\n",
    "                print(f\"🛑 Stopping epoch {epoch+1} due to NaN issues\")\n",
    "                break\n",
    "            \n",
    "            x = x.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Check input data\n",
    "            if nan_detector.check_tensor(x, \"input_x\") or nan_detector.check_tensor(labels, \"input_labels\"):\n",
    "                print(f\"⚠️  Skipping batch {batch_idx} due to NaN in input\")\n",
    "                continue\n",
    "            \n",
    "            # Training steps\n",
    "            for _ in range(config[\"discriminator_steps\"]):\n",
    "                disc_loss = discriminator_training_step(x, labels, epoch)\n",
    "                if not np.isnan(disc_loss):\n",
    "                    epoch_losses['disc'].append(disc_loss)\n",
    "            \n",
    "            for _ in range(config[\"generator_steps\"]):\n",
    "                gen_losses = generator_training_step(x, labels, epoch)\n",
    "                \n",
    "                # Only add non-NaN losses\n",
    "                for key, value in gen_losses.items():\n",
    "                    if not np.isnan(value):\n",
    "                        epoch_losses[key].append(value)\n",
    "            \n",
    "            batch_count += 1\n",
    "            \n",
    "            # Periodic logging\n",
    "            if batch_idx % 1 == 0:  # More frequent logging\n",
    "                print(f\"\\n📈 Epoch {epoch+1}/{config['epochs']}, Batch {batch_idx}\")\n",
    "                print(f\"   NaN count: {nan_detector.nan_count}\")\n",
    "                \n",
    "                # Log recent losses\n",
    "                for key in ['disc', 'total_G', 'recon']:\n",
    "                    if epoch_losses[key]:\n",
    "                        recent_losses = epoch_losses[key][-config[\"generator_steps\"]:]\n",
    "                        avg_loss = np.mean(recent_losses)\n",
    "                        print(f\"   {key}: {avg_loss:.4f}\")\n",
    "                \n",
    "                # Memory usage\n",
    "                if torch.cuda.is_available():\n",
    "                    print(f\"   GPU Memory: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")\n",
    "        \n",
    "        # End of epoch processing\n",
    "        if not nan_detector.should_stop() and batch_count > 0:\n",
    "            # Update learning rate schedulers\n",
    "            if epoch_losses['disc']:\n",
    "                scheduler_D.step(np.mean(epoch_losses['disc']))\n",
    "            if epoch_losses['total_G']:\n",
    "                scheduler_G.step(np.mean(epoch_losses['total_G']))\n",
    "            \n",
    "            # Add to history\n",
    "            for key in loss_history.keys():\n",
    "                if epoch_losses[key]:\n",
    "                    loss_history[key].extend(epoch_losses[key])\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if (epoch + 1) % config[\"save_interval\"] == 0:\n",
    "                save_checkpoint(epoch + 1, {'loss_history': loss_history})\n",
    "            \n",
    "            # Epoch summary\n",
    "            print(f\"\\n✅ Epoch {epoch+1} completed:\")\n",
    "            for key in ['disc', 'total_G', 'recon']:\n",
    "                if epoch_losses[key]:\n",
    "                    print(f\"   {key}: {np.mean(epoch_losses[key]):.4f}\")\n",
    "            print(f\"   Batches processed: {batch_count}\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        # Clear cache periodically\n",
    "        if torch.cuda.is_available() and epoch % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n⏹️  Training interrupted by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Training error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    # Final checkpoint\n",
    "    save_checkpoint(epoch + 1, {'loss_history': loss_history, 'final_checkpoint': True})\n",
    "    \n",
    "    # Plot results if we have data\n",
    "    if any(loss_history[key] for key in loss_history.keys()):\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        valid_loss_groups = []\n",
    "        for loss_name in ['disc', 'total_G', 'recon', 'disent', 'cont', 'adv_gen']:\n",
    "            if loss_history[loss_name]:\n",
    "                valid_loss_groups.append((loss_name, loss_name.replace('_', ' ').title()))\n",
    "        \n",
    "        if valid_loss_groups:\n",
    "            n_plots = len(valid_loss_groups)\n",
    "            cols = 3\n",
    "            rows = (n_plots + cols - 1) // cols\n",
    "            \n",
    "            fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "            if rows == 1:\n",
    "                axes = [axes] if cols == 1 else axes\n",
    "            else:\n",
    "                axes = axes.flatten()\n",
    "            \n",
    "            for i, (loss_name, title) in enumerate(valid_loss_groups):\n",
    "                values = loss_history[loss_name]\n",
    "                if len(values) > 100:\n",
    "                    # Moving average for smoother visualization\n",
    "                    window = max(1, len(values) // 100)\n",
    "                    smoothed = np.convolve(values, np.ones(window)/window, mode='valid')\n",
    "                    axes[i].plot(smoothed, label=f'{loss_name} (smoothed)', linewidth=2)\n",
    "                \n",
    "                axes[i].plot(values, alpha=0.3, label=f'{loss_name} (raw)')\n",
    "                axes[i].set_title(title)\n",
    "                axes[i].set_xlabel('Iteration')\n",
    "                axes[i].set_ylabel('Loss')\n",
    "                axes[i].legend()\n",
    "                axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Hide unused subplots\n",
    "            for i in range(len(valid_loss_groups), len(axes)):\n",
    "                axes[i].set_visible(False)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(config[\"save_dir\"], \"loss_curves.png\"), \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "    \n",
    "    print(f\"\\n🎯 Training session completed!\")\n",
    "    print(f\"   Total NaN occurrences: {nan_detector.nan_count}\")\n",
    "    print(f\"   Checkpoints saved in: {config['save_dir']}\")\n",
    "    print(f\"   Final learning rates - G: {scheduler_G.get_last_lr()}, D: {scheduler_D.get_last_lr()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b272a25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "🔧 Initializing models...\n",
      "✅ style_encoder initialized\n",
      "✅ content_encoder initialized\n",
      "✅ discriminator initialized\n",
      "✅ decoder initialized\n",
      "🔧 Setting up optimizers and schedulers...\n",
      "🔧 Setting up dataloader...\n",
      "✅ DataLoader created successfully with batch_size=8\n",
      "🚀 Starting training with enhanced NaN protection...\n",
      "📊 Configuration: {'style_dim': 256, 'content_dim': 256, 'transformer_heads': 4, 'transformer_layers': 4, 'cnn_channels': [16, 32, 64, 128, 256], 'epochs': 100, 'batch_size': 8, 'lr': 5e-05, 'beta1': 0.5, 'beta2': 0.999, 'weight_decay': 1e-05, 'lambda_adv_disc': 0.8, 'lambda_adv_gen': 0.1, 'lambda_disent': 0.3, 'lambda_cont': 0.2, 'lambda_margin': 0.1, 'lambda_recon': 2.0, 'grad_clip_value': 0.5, 'warmup_epochs': 5, 'nan_threshold': 5, 'piano_dir': 'dataset/train/piano', 'violin_dir': 'dataset/train/violin', 'stats_path': 'stats_stft_cqt.npz', 'save_dir': 'checkpoints', 'save_interval': 10, 'discriminator_steps': 1, 'generator_steps': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Epoch 1/100\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Batch 1:\n",
      "   Discriminator Loss: 1.593956\n",
      "   Generator Total Loss: 7.046389\n",
      "     Adv Gen: -0.693144\n",
      "     Disent: 0.008900\n",
      "     Cont: 1.943153\n",
      "     Margin: 0.000000\n",
      "     Recon: 3.490996\n",
      "   Consecutive NaN count: 0\n",
      "\n",
      "📊 Batch 2:\n",
      "   Discriminator Loss: 1.593772\n",
      "   Generator Total Loss: 6.424905\n",
      "     Adv Gen: -0.693145\n",
      "     Disent: 0.003024\n",
      "     Cont: 1.902855\n",
      "     Margin: 0.000000\n",
      "     Recon: 3.181236\n",
      "   Consecutive NaN count: 0\n",
      "\n",
      "📊 Batch 3:\n",
      "   Discriminator Loss: 1.593267\n",
      "   Generator Total Loss: 11.224684\n",
      "     Adv Gen: -0.693145\n",
      "     Disent: 0.000838\n",
      "     Cont: 1.906530\n",
      "     Margin: 0.000000\n",
      "     Recon: 5.581118\n",
      "   Consecutive NaN count: 0\n",
      "\n",
      "📊 Batch 4:\n",
      "   Discriminator Loss: 1.593601\n",
      "   Generator Total Loss: 7.152896\n",
      "     Adv Gen: -0.693146\n",
      "     Disent: 0.000788\n",
      "     Cont: 1.964319\n",
      "     Margin: 0.000000\n",
      "     Recon: 3.544070\n",
      "   Consecutive NaN count: 0\n",
      "\n",
      "📊 Batch 5:\n",
      "   Discriminator Loss: 1.592313\n",
      "   Generator Total Loss: 7.774140\n",
      "     Adv Gen: -0.693146\n",
      "     Disent: 0.001034\n",
      "     Cont: 1.769073\n",
      "     Margin: 0.000000\n",
      "     Recon: 3.858589\n",
      "   Consecutive NaN count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [01:22<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏹️  Training interrupted by user\n",
      "\n",
      "💾 Saving final checkpoint...\n",
      "💾 Checkpoint saved: checkpoints/checkpoint_epoch_1.pth\n",
      "\n",
      "🎯 Training completed!\n",
      "   Total epochs processed: 1\n",
      "   Final consecutive NaN count: 0\n",
      "   Checkpoints saved in: checkpoints\n",
      "🎉 Training session finished successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from style_encoder import StyleEncoder\n",
    "from content_encoder import ContentEncoder\n",
    "from discriminator import Discriminator\n",
    "from new_decoder import Decoder, compute_comprehensive_loss\n",
    "from losses import (infoNCE_loss, margin_loss, adversarial_loss, \n",
    "                   disentanglement_loss)\n",
    "from Dataloader import get_dataloader\n",
    "\n",
    "# ================================================================\n",
    "# CONFIGURAZIONE DISPOSITIVO E MEMORIA\n",
    "# ================================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
    "    print(f\"Memory reserved: {torch.cuda.memory_reserved()/1024**2:.2f} MB\")\n",
    "\n",
    "# ================================================================\n",
    "# CONFIGURAZIONE TRAINING\n",
    "# ================================================================\n",
    "config = {\n",
    "    # Architettura - parametri originali richiesti\n",
    "    \"style_dim\": 256,\n",
    "    \"content_dim\": 256,\n",
    "    \"transformer_heads\": 4,\n",
    "    \"transformer_layers\": 4,\n",
    "    \"cnn_channels\": [16, 32, 64, 128, 256],\n",
    "    \n",
    "    # Training - parametri conservativi per stabilità\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 8,          # Ridotto per evitare OOM\n",
    "    \"lr\": 5e-5,              # Learning rate conservativo\n",
    "    \"beta1\": 0.5,\n",
    "    \"beta2\": 0.999,\n",
    "    \"weight_decay\": 1e-5,    # Weight decay per prevenire overfitting\n",
    "    \n",
    "    # Pesi delle loss - bilanciati per stabilità\n",
    "    \"lambda_adv_disc\": 0.8,\n",
    "    \"lambda_adv_gen\": 0.1,\n",
    "    \"lambda_disent\": 0.3,\n",
    "    \"lambda_cont\": 0.2,\n",
    "    \"lambda_margin\": 0.1,\n",
    "    \"lambda_recon\": 2.0,\n",
    "    \n",
    "    # Controlli di stabilità\n",
    "    \"grad_clip_value\": 0.5,      # Gradient clipping conservativo\n",
    "    \"warmup_epochs\": 5,          # Epochs di warmup\n",
    "    \"nan_threshold\": 5,          # Max NaN consecutivi prima di fermarsi\n",
    "    \n",
    "    # Percorsi dati\n",
    "    \"piano_dir\": \"dataset/train/piano\",\n",
    "    \"violin_dir\": \"dataset/train/violin\",\n",
    "    \"stats_path\": \"stats_stft_cqt.npz\",\n",
    "    \n",
    "    # Salvataggio\n",
    "    \"save_dir\": \"checkpoints\",\n",
    "    \"save_interval\": 10,\n",
    "    \n",
    "    # Strategia di training\n",
    "    \"discriminator_steps\": 1,\n",
    "    \"generator_steps\": 1,\n",
    "}\n",
    "\n",
    "# Crea directory di salvataggio\n",
    "os.makedirs(config[\"save_dir\"], exist_ok=True)\n",
    "\n",
    "# ================================================================\n",
    "# INIZIALIZZAZIONE PESI CONSERVATIVA\n",
    "# ================================================================\n",
    "def init_weights_conservative(m):\n",
    "    \"\"\"\n",
    "    Inizializzazione conservativa dei pesi per prevenire NaN\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        # Xavier uniforme con gain ridotto\n",
    "        nn.init.xavier_uniform_(m.weight, gain=0.2)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        # Xavier uniforme con gain ridotto\n",
    "        nn.init.xavier_uniform_(m.weight, gain=0.2)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "# ================================================================\n",
    "# FUNZIONI DI UTILITÀ\n",
    "# ================================================================\n",
    "def check_for_nan(*tensors, names=None):\n",
    "    \"\"\"\n",
    "    Controlla se ci sono NaN o Inf nei tensori\n",
    "    \n",
    "    Args:\n",
    "        *tensors: Tensori da controllare\n",
    "        names: Nomi dei tensori per il debug\n",
    "    \n",
    "    Returns:\n",
    "        bool: True se trovati NaN/Inf\n",
    "    \"\"\"\n",
    "    if names is None:\n",
    "        names = [f\"tensor_{i}\" for i in range(len(tensors))]\n",
    "    \n",
    "    for tensor, name in zip(tensors, names):\n",
    "        if torch.isnan(tensor).any():\n",
    "            print(f\"🚨 NaN detected in {name}\")\n",
    "            return True\n",
    "        if torch.isinf(tensor).any():\n",
    "            print(f\"🚨 Inf detected in {name}\")\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def set_requires_grad(models, requires_grad):\n",
    "    \"\"\"\n",
    "    Abilita/disabilita i gradienti per i modelli\n",
    "    \n",
    "    Args:\n",
    "        models: Modello singolo o lista di modelli\n",
    "        requires_grad: True per abilitare, False per disabilitare\n",
    "    \"\"\"\n",
    "    if not isinstance(models, list):\n",
    "        models = [models]\n",
    "    for model in models:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "def get_learning_rate_multiplier(epoch, warmup_epochs):\n",
    "    \"\"\"\n",
    "    Calcola il moltiplicatore del learning rate per il warmup\n",
    "    \n",
    "    Args:\n",
    "        epoch: Epoca corrente\n",
    "        warmup_epochs: Numero di epoche di warmup\n",
    "    \n",
    "    Returns:\n",
    "        float: Moltiplicatore del learning rate\n",
    "    \"\"\"\n",
    "    if epoch < warmup_epochs:\n",
    "        return (epoch + 1) / warmup_epochs\n",
    "    return 1.0\n",
    "\n",
    "def save_checkpoint(epoch, models_dict, optimizers_dict, schedulers_dict, config):\n",
    "    \"\"\"\n",
    "    Salva checkpoint completo\n",
    "    \n",
    "    Args:\n",
    "        epoch: Epoca corrente\n",
    "        models_dict: Dizionario dei modelli\n",
    "        optimizers_dict: Dizionario degli ottimizzatori\n",
    "        schedulers_dict: Dizionario degli schedulers\n",
    "        config: Configurazione\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'config': config\n",
    "    }\n",
    "    \n",
    "    # Salva stati dei modelli\n",
    "    for name, model in models_dict.items():\n",
    "        checkpoint[name] = model.state_dict()\n",
    "    \n",
    "    # Salva stati degli ottimizzatori\n",
    "    for name, optimizer in optimizers_dict.items():\n",
    "        checkpoint[name] = optimizer.state_dict()\n",
    "    \n",
    "    # Salva stati degli schedulers\n",
    "    for name, scheduler in schedulers_dict.items():\n",
    "        checkpoint[name] = scheduler.state_dict()\n",
    "    \n",
    "    checkpoint_path = os.path.join(config[\"save_dir\"], f\"checkpoint_epoch_{epoch}.pth\")\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"💾 Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "# ================================================================\n",
    "# INIZIALIZZAZIONE MODELLI\n",
    "# ================================================================\n",
    "print(\"🔧 Initializing models...\")\n",
    "\n",
    "style_encoder = StyleEncoder(\n",
    "    cnn_out_dim=config[\"style_dim\"],\n",
    "    transformer_dim=config[\"style_dim\"],\n",
    "    num_heads=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"]\n",
    ").to(device)\n",
    "\n",
    "content_encoder = ContentEncoder(\n",
    "    cnn_out_dim=config[\"content_dim\"],\n",
    "    transformer_dim=config[\"content_dim\"],\n",
    "    num_heads=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"],\n",
    "    channels_list=config[\"cnn_channels\"]\n",
    ").to(device)\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    input_dim=config[\"style_dim\"],\n",
    "    hidden_dim=128\n",
    ").to(device)\n",
    "\n",
    "decoder = Decoder(\n",
    "    d_model=config[\"style_dim\"],\n",
    "    nhead=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"]\n",
    ").to(device)\n",
    "\n",
    "# Applica inizializzazione conservativa\n",
    "models = [style_encoder, content_encoder, discriminator, decoder]\n",
    "model_names = [\"style_encoder\", \"content_encoder\", \"discriminator\", \"decoder\"]\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    model.apply(init_weights_conservative)\n",
    "    print(f\"✅ {name} initialized\")\n",
    "\n",
    "# ================================================================\n",
    "# OTTIMIZZATORI E SCHEDULERS\n",
    "# ================================================================\n",
    "print(\"🔧 Setting up optimizers and schedulers...\")\n",
    "\n",
    "# Ottimizzatori con AdamW per maggiore stabilità\n",
    "optimizer_G = optim.AdamW(\n",
    "    list(style_encoder.parameters()) + \n",
    "    list(content_encoder.parameters()) + \n",
    "    list(decoder.parameters()),\n",
    "    lr=config[\"lr\"],\n",
    "    betas=(config[\"beta1\"], config[\"beta2\"]),\n",
    "    weight_decay=config[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "optimizer_D = optim.AdamW(\n",
    "    discriminator.parameters(),\n",
    "    lr=config[\"lr\"],\n",
    "    betas=(config[\"beta1\"], config[\"beta2\"]),\n",
    "    weight_decay=config[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "# Schedulers per learning rate adattivo\n",
    "scheduler_G = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_G, mode='min', factor=0.7, patience=5\n",
    ")\n",
    "\n",
    "scheduler_D = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_D, mode='min', factor=0.7, patience=5\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "# DATALOADER\n",
    "# ================================================================\n",
    "print(\"🔧 Setting up dataloader...\")\n",
    "\n",
    "try:\n",
    "    train_loader = get_dataloader(\n",
    "        piano_dir=config[\"piano_dir\"],\n",
    "        violin_dir=config[\"violin_dir\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        stats_path=config[\"stats_path\"]\n",
    "    )\n",
    "    print(f\"✅ DataLoader created successfully with batch_size={config['batch_size']}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating DataLoader: {e}\")\n",
    "    raise\n",
    "\n",
    "# ================================================================\n",
    "# FUNZIONI DI TRAINING\n",
    "# ================================================================\n",
    "def discriminator_training_step(x, labels, epoch):\n",
    "    \"\"\"\n",
    "    Step di training per il discriminatore\n",
    "    \n",
    "    Args:\n",
    "        x: Input batch\n",
    "        labels: Labels del batch\n",
    "        epoch: Epoca corrente\n",
    "    \n",
    "    Returns:\n",
    "        float: Loss del discriminatore\n",
    "    \"\"\"\n",
    "    # Abilita gradienti solo per discriminatore\n",
    "    set_requires_grad(discriminator, True)\n",
    "    set_requires_grad([style_encoder, content_encoder, decoder], False)\n",
    "    \n",
    "    try:\n",
    "        # Forward pass senza gradienti per i generatori\n",
    "        with torch.no_grad():\n",
    "            style_emb, class_emb = style_encoder(x, labels)\n",
    "            content_emb = content_encoder(x)\n",
    "        \n",
    "        # Controllo NaN negli embeddings\n",
    "        if check_for_nan(style_emb, class_emb, content_emb, \n",
    "                         names=[\"style_emb\", \"class_emb\", \"content_emb\"]):\n",
    "            return float('nan')\n",
    "        \n",
    "        # Calcola loss del discriminatore\n",
    "        disc_loss, _ = adversarial_loss(\n",
    "            style_emb.detach(),\n",
    "            class_emb.detach(),\n",
    "            content_emb.detach(),\n",
    "            discriminator,\n",
    "            labels,\n",
    "            compute_for_discriminator=True,\n",
    "            lambda_content=config[\"lambda_adv_disc\"]\n",
    "        )\n",
    "        \n",
    "        # Controllo NaN nella loss\n",
    "        if check_for_nan(disc_loss, names=[\"disc_loss\"]):\n",
    "            return float('nan')\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer_D.zero_grad()\n",
    "        disc_loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(discriminator.parameters(), config[\"grad_clip_value\"])\n",
    "        \n",
    "        # Controllo gradienti per NaN\n",
    "        for name, param in discriminator.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                if check_for_nan(param.grad, names=[f\"discriminator.{name}.grad\"]):\n",
    "                    return float('nan')\n",
    "        \n",
    "        optimizer_D.step()\n",
    "        return disc_loss.item()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in discriminator training step: {e}\")\n",
    "        return float('nan')\n",
    "\n",
    "def generator_training_step(x, labels, epoch):\n",
    "    \"\"\"\n",
    "    Step di training per i generatori\n",
    "    \n",
    "    Args:\n",
    "        x: Input batch\n",
    "        labels: Labels del batch\n",
    "        epoch: Epoca corrente\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dizionario con tutte le loss\n",
    "    \"\"\"\n",
    "    # Abilita gradienti per i generatori\n",
    "    set_requires_grad([style_encoder, content_encoder, decoder], True)\n",
    "    set_requires_grad(discriminator, False)\n",
    "    \n",
    "    try:\n",
    "        # Forward pass\n",
    "        style_emb, class_emb = style_encoder(x, labels)\n",
    "        content_emb = content_encoder(x)\n",
    "        \n",
    "        # Controllo NaN negli embeddings\n",
    "        if check_for_nan(style_emb, class_emb, content_emb,\n",
    "                         names=[\"style_emb\", \"class_emb\", \"content_emb\"]):\n",
    "            return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "        \n",
    "        # Calcola loss avversariale per il generatore\n",
    "        _, adv_gen_loss = adversarial_loss(\n",
    "            style_emb,\n",
    "            class_emb,\n",
    "            content_emb,\n",
    "            discriminator,\n",
    "            labels,\n",
    "            compute_for_discriminator=False,\n",
    "            lambda_content=config[\"lambda_adv_gen\"]\n",
    "        )\n",
    "        \n",
    "        # Calcola loss di disentanglement\n",
    "        disent_loss = disentanglement_loss(\n",
    "            style_emb,\n",
    "            content_emb.mean(dim=1),\n",
    "            use_hsic=True\n",
    "        )\n",
    "        \n",
    "        # Calcola loss contrastiva\n",
    "        cont_loss = infoNCE_loss(style_emb, labels)\n",
    "        \n",
    "        # Calcola margin loss\n",
    "        margin_loss_val = margin_loss(class_emb)\n",
    "        \n",
    "        # Calcola loss di ricostruzione\n",
    "        stft_part = x[:, :, :, :, :513]\n",
    "        recon_x = decoder(content_emb, style_emb, y=stft_part)\n",
    "        recon_losses = compute_comprehensive_loss(recon_x, stft_part)\n",
    "        recon_loss = recon_losses['total_loss']\n",
    "        \n",
    "        # Controllo NaN in tutte le loss\n",
    "        losses = [adv_gen_loss, disent_loss, cont_loss, margin_loss_val, recon_loss]\n",
    "        loss_names = ['adv_gen_loss', 'disent_loss', 'cont_loss', 'margin_loss', 'recon_loss']\n",
    "        \n",
    "        if check_for_nan(*losses, names=loss_names):\n",
    "            return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "        \n",
    "        # Calcola loss totale con warmup\n",
    "        lr_multiplier = get_learning_rate_multiplier(epoch, config[\"warmup_epochs\"])\n",
    "        warmup_factor = lr_multiplier if epoch < config[\"warmup_epochs\"] else 1.0\n",
    "        \n",
    "        total_G_loss = (\n",
    "            config[\"lambda_adv_gen\"] * adv_gen_loss * warmup_factor +\n",
    "            config[\"lambda_disent\"] * disent_loss * warmup_factor +\n",
    "            config[\"lambda_cont\"] * cont_loss * warmup_factor +\n",
    "            config[\"lambda_margin\"] * margin_loss_val * warmup_factor +\n",
    "            config[\"lambda_recon\"] * recon_loss\n",
    "        )\n",
    "        \n",
    "        # Controllo NaN nella loss totale\n",
    "        if check_for_nan(total_G_loss, names=[\"total_G_loss\"]):\n",
    "            return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer_G.zero_grad()\n",
    "        total_G_loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        generator_params = (\n",
    "            list(style_encoder.parameters()) + \n",
    "            list(content_encoder.parameters()) +\n",
    "            list(decoder.parameters())\n",
    "        )\n",
    "        torch.nn.utils.clip_grad_norm_(generator_params, config[\"grad_clip_value\"])\n",
    "        \n",
    "        # Controllo gradienti per NaN\n",
    "        for model, model_name in [(style_encoder, \"style_encoder\"), \n",
    "                                 (content_encoder, \"content_encoder\"), \n",
    "                                 (decoder, \"decoder\")]:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    if check_for_nan(param.grad, names=[f\"{model_name}.{name}.grad\"]):\n",
    "                        return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        \n",
    "        return {\n",
    "            'total_G': total_G_loss.item(),\n",
    "            'adv_gen': adv_gen_loss.item(),\n",
    "            'disent': disent_loss.item(),\n",
    "            'cont': cont_loss.item(),\n",
    "            'margin': margin_loss_val.item(),\n",
    "            'recon': recon_loss.item()\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in generator training step: {e}\")\n",
    "        return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "\n",
    "# ================================================================\n",
    "# CICLO DI TRAINING PRINCIPALE\n",
    "# ================================================================\n",
    "print(\"🚀 Starting training with enhanced NaN protection...\")\n",
    "print(f\"📊 Configuration: {config}\")\n",
    "\n",
    "# Inizializza strutture per il tracking delle loss\n",
    "loss_history = {\n",
    "    'total_G': [],\n",
    "    'disc': [],\n",
    "    'disent': [],\n",
    "    'cont': [],\n",
    "    'margin': [],\n",
    "    'recon': [],\n",
    "    'adv_gen': []\n",
    "}\n",
    "\n",
    "# Contatore per NaN consecutivi\n",
    "consecutive_nan_count = 0\n",
    "max_consecutive_nans = config[\"nan_threshold\"]\n",
    "\n",
    "# Dizionari per salvataggio\n",
    "models_dict = {\n",
    "    'style_encoder': style_encoder,\n",
    "    'content_encoder': content_encoder,\n",
    "    'discriminator': discriminator,\n",
    "    'decoder': decoder\n",
    "}\n",
    "\n",
    "optimizers_dict = {\n",
    "    'optimizer_G': optimizer_G,\n",
    "    'optimizer_D': optimizer_D\n",
    "}\n",
    "\n",
    "schedulers_dict = {\n",
    "    'scheduler_G': scheduler_G,\n",
    "    'scheduler_D': scheduler_D\n",
    "}\n",
    "\n",
    "try:\n",
    "    for epoch in tqdm(range(config[\"epochs\"]), desc=\"Training Progress\"):\n",
    "        # Controllo early stopping per NaN\n",
    "        if consecutive_nan_count >= max_consecutive_nans:\n",
    "            print(f\"🛑 Early stopping: {consecutive_nan_count} consecutive NaN occurrences\")\n",
    "            break\n",
    "        \n",
    "        # Imposta tutti i modelli in modalità training\n",
    "        for model in models:\n",
    "            model.train()\n",
    "        \n",
    "        # Tracking delle loss per l'epoca corrente\n",
    "        epoch_losses = {key: [] for key in loss_history.keys()}\n",
    "        \n",
    "        print(f\"\\n🔄 Epoch {epoch+1}/{config['epochs']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            # Trasferisce dati su GPU\n",
    "            x = x.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Controllo NaN nei dati di input\n",
    "            if check_for_nan(x, labels, names=[\"input_x\", \"input_labels\"]):\n",
    "                print(f\"⚠️  Skipping batch {batch_idx} due to NaN in input data\")\n",
    "                continue\n",
    "            \n",
    "            # ============================================\n",
    "            # TRAINING DISCRIMINATORE\n",
    "            # ============================================\n",
    "            for _ in range(config[\"discriminator_steps\"]):\n",
    "                disc_loss = discriminator_training_step(x, labels, epoch)\n",
    "                \n",
    "                if not np.isnan(disc_loss):\n",
    "                    epoch_losses['disc'].append(disc_loss)\n",
    "                    consecutive_nan_count = 0  # Reset counter su successo\n",
    "                else:\n",
    "                    consecutive_nan_count += 1\n",
    "                    print(f\"⚠️  NaN in discriminator loss (consecutive: {consecutive_nan_count})\")\n",
    "            \n",
    "            # ============================================\n",
    "            # TRAINING GENERATORE\n",
    "            # ============================================\n",
    "            for _ in range(config[\"generator_steps\"]):\n",
    "                gen_losses = generator_training_step(x, labels, epoch)\n",
    "                \n",
    "                # Controlla se ci sono NaN nelle loss del generatore\n",
    "                nan_in_gen = any(np.isnan(v) for v in gen_losses.values())\n",
    "                \n",
    "                if not nan_in_gen:\n",
    "                    # Aggiungi loss valide alla storia\n",
    "                    for key, value in gen_losses.items():\n",
    "                        if key in epoch_losses:\n",
    "                            epoch_losses[key].append(value)\n",
    "                    consecutive_nan_count = 0  # Reset counter su successo\n",
    "                else:\n",
    "                    consecutive_nan_count += 1\n",
    "                    print(f\"⚠️  NaN in generator losses (consecutive: {consecutive_nan_count})\")\n",
    "            \n",
    "            # ============================================\n",
    "            # LOGGING PER BATCH\n",
    "            # ============================================\n",
    "            # Stampa loss dettagliate per ogni batch\n",
    "            print(f\"\\n📊 Batch {batch_idx + 1}:\")\n",
    "            \n",
    "            # Loss del discriminatore\n",
    "            if epoch_losses['disc']:\n",
    "                recent_disc = epoch_losses['disc'][-config[\"discriminator_steps\"]:]\n",
    "                avg_disc = np.mean(recent_disc)\n",
    "                print(f\"   Discriminator Loss: {avg_disc:.6f}\")\n",
    "            \n",
    "            # Loss del generatore\n",
    "            if epoch_losses['total_G']:\n",
    "                recent_gen = epoch_losses['total_G'][-config[\"generator_steps\"]:]\n",
    "                avg_total_G = np.mean(recent_gen)\n",
    "                print(f\"   Generator Total Loss: {avg_total_G:.6f}\")\n",
    "            \n",
    "            # Loss individuali del generatore\n",
    "            gen_loss_names = ['adv_gen', 'disent', 'cont', 'margin', 'recon']\n",
    "            for loss_name in gen_loss_names:\n",
    "                if epoch_losses[loss_name]:\n",
    "                    recent_loss = epoch_losses[loss_name][-config[\"generator_steps\"]:]\n",
    "                    avg_loss = np.mean(recent_loss)\n",
    "                    print(f\"     {loss_name.replace('_', ' ').title()}: {avg_loss:.6f}\")\n",
    "            \n",
    "            # Informazioni aggiuntive\n",
    "            print(f\"   Consecutive NaN count: {consecutive_nan_count}\")\n",
    "            if torch.cuda.is_available():\n",
    "                print(f\"   GPU Memory: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")\n",
    "            \n",
    "            # Controllo early stopping durante il batch\n",
    "            if consecutive_nan_count >= max_consecutive_nans:\n",
    "                print(f\"🛑 Stopping epoch {epoch+1} due to consecutive NaN issues\")\n",
    "                break\n",
    "        \n",
    "        # ============================================\n",
    "        # FINE EPOCA: AGGIORNAMENTI E SALVATAGGIO\n",
    "        # ============================================\n",
    "        if consecutive_nan_count < max_consecutive_nans:\n",
    "            # Aggiorna schedulers\n",
    "            if epoch_losses['disc']:\n",
    "                scheduler_D.step(np.mean(epoch_losses['disc']))\n",
    "            if epoch_losses['total_G']:\n",
    "                scheduler_G.step(np.mean(epoch_losses['total_G']))\n",
    "            \n",
    "            # Aggiungi loss dell'epoca alla storia globale\n",
    "            for key in loss_history.keys():\n",
    "                if epoch_losses[key]:\n",
    "                    loss_history[key].extend(epoch_losses[key])\n",
    "            \n",
    "            # Salva checkpoint periodicamente\n",
    "            if (epoch + 1) % config[\"save_interval\"] == 0:\n",
    "                save_checkpoint(epoch + 1, models_dict, optimizers_dict, schedulers_dict, config)\n",
    "            \n",
    "            # Riepilogo dell'epoca\n",
    "            print(f\"\\n✅ Epoch {epoch+1} Summary:\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            for key in ['disc', 'total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']:\n",
    "                if epoch_losses[key]:\n",
    "                    avg_loss = np.mean(epoch_losses[key])\n",
    "                    print(f\"   {key.replace('_', ' ').title()}: {avg_loss:.6f}\")\n",
    "            \n",
    "            # Informazioni sui learning rates\n",
    "            current_lr_G = optimizer_G.param_groups[0]['lr']\n",
    "            current_lr_D = optimizer_D.param_groups[0]['lr']\n",
    "            print(f\"   LR Generator: {current_lr_G:.2e}\")\n",
    "            print(f\"   LR Discriminator: {current_lr_D:.2e}\")\n",
    "            \n",
    "            print(\"-\" * 60)\n",
    "        \n",
    "        # Pulizia memoria periodica\n",
    "        if torch.cuda.is_available() and epoch % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n⏹️  Training interrupted by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Training error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    # Salvataggio finale\n",
    "    print(\"\\n💾 Saving final checkpoint...\")\n",
    "    save_checkpoint(epoch + 1, models_dict, optimizers_dict, schedulers_dict, config)\n",
    "    \n",
    "    # Visualizzazione delle loss\n",
    "    if any(loss_history[key] for key in loss_history.keys()):\n",
    "        print(\"📊 Generating loss plots...\")\n",
    "        \n",
    "        # Configura plot\n",
    "        plt.style.use('default')\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Definisci le loss da plottare\n",
    "        loss_configs = [\n",
    "            ('disc', 'Discriminator Loss', 'red'),\n",
    "            ('total_G', 'Generator Total Loss', 'blue'),\n",
    "            ('recon', 'Reconstruction Loss', 'green'),\n",
    "            ('adv_gen', 'Adversarial Generator Loss', 'orange'),\n",
    "            ('disent', 'Disentanglement Loss', 'purple'),\n",
    "            ('cont', 'Contrastive Loss', 'brown')\n",
    "        ]\n",
    "        \n",
    "        for i, (loss_name, title, color) in enumerate(loss_configs):\n",
    "            if loss_history[loss_name]:\n",
    "                values = loss_history[loss_name]\n",
    "                \n",
    "                # Plot raw values\n",
    "                axes[i].plot(values, alpha=0.4, color=color, linewidth=0.5, label='Raw')\n",
    "                \n",
    "                # Plot smoothed values se ci sono abbastanza punti\n",
    "                if len(values) > 50:\n",
    "                    window = max(1, len(values) // 50)\n",
    "                    smoothed = np.convolve(values, np.ones(window)/window, mode='valid')\n",
    "                    axes[i].plot(smoothed, color=color, linewidth=2, label='Smoothed')\n",
    "                \n",
    "                axes[i].set_title(title, fontsize=12, fontweight='bold')\n",
    "                axes[i].set_xlabel('Iteration')\n",
    "                axes[i].set_ylabel('Loss')\n",
    "                axes[i].legend()\n",
    "                axes[i].grid(True, alpha=0.3)\n",
    "                axes[i].set_xlim(0, len(values))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plot_path = os.path.join(config[\"save_dir\"], \"loss_curves.png\")\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"📈 Loss curves saved to: {plot_path}\")\n",
    "    \n",
    "    # Riepilogo finale\n",
    "    print(f\"\\n🎯 Training completed!\")\n",
    "    print(f\"   Total epochs processed: {epoch + 1}\")\n",
    "    print(f\"   Final consecutive NaN count: {consecutive_nan_count}\")\n",
    "    print(f\"   Checkpoints saved in: {config['save_dir']}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   Final GPU memory: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")\n",
    "    \n",
    "    print(\"🎉 Training session finished successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48112f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
