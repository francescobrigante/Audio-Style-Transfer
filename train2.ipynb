{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9588c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from utilityFunctions import *\n",
    "\n",
    "from style_encoder import StyleEncoder\n",
    "from content_encoder import ContentEncoder\n",
    "from discriminator import Discriminator\n",
    "from new_decoder import Decoder, compute_comprehensive_loss\n",
    "from losses import (infoNCE_loss, margin_loss, adversarial_loss, \n",
    "                   disentanglement_loss)\n",
    "from dataloader import get_dataloader\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "608babe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train parameters\n",
    "config = {\n",
    "    \"style_dim\": 256,\n",
    "    \"content_dim\": 256,\n",
    "    \"transformer_heads\": 4,\n",
    "    \"transformer_layers\": 4,\n",
    "    \"cnn_channels\": [16, 32, 64, 128, 256],\n",
    "    \n",
    "    # Training params\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 16,          \n",
    "    \"lr_gen\": 3e-5,\n",
    "    \"lr_disc\": 1e-5,\n",
    "    \"beta1\": 0.5,\n",
    "    \"beta2\": 0.999,\n",
    "    \"weight_decay\": 1e-4, \n",
    "    \n",
    "    # losses weights\n",
    "    \"lambda_adv_disc\": 1.0,\n",
    "    \"lambda_adv_gen\": 0.5,\n",
    "    \"lambda_disent\": 1.0,\n",
    "    \"lambda_cont\": 0.5,\n",
    "    \"lambda_margin\": 0.5,\n",
    "    \"lambda_recon\": 5.0,\n",
    "    \n",
    "    # for stability\n",
    "    \"grad_clip_value\": 0.5, \n",
    "    \"warmup_epochs\": 5,\n",
    "    \"nan_threshold\": 5,          # Max NaN consecutivi\n",
    "    \n",
    "    # paths\n",
    "    \"piano_dir\": \"dataset/train/piano\",\n",
    "    \"violin_dir\": \"dataset/train/violin\",\n",
    "    \"stats_path\": \"stats_stft_cqt.npz\",\n",
    "    \n",
    "    # save\n",
    "    \"save_dir\": \"checkpoints\",\n",
    "    \"save_interval\": 10,\n",
    "    \n",
    "    # training strategy ----> EXPERIMENT WITH DIFFERENT VALUES e.g. 10\n",
    "    \"discriminator_steps\": 3,\n",
    "    \"generator_steps\": 5,\n",
    "}\n",
    "\n",
    "os.makedirs(config[\"save_dir\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5389e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conservative weight initialization\n",
    "def init_weights_conservative(m):\n",
    "    \"\"\"\n",
    "    Inizializzazione conservativa dei pesi per prevenire NaN\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        # Xavier uniforme con gain ridotto\n",
    "        nn.init.xavier_uniform_(m.weight, gain=0.2)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        # Xavier uniforme con gain ridotto\n",
    "        nn.init.xavier_uniform_(m.weight, gain=0.2)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "# utility functions\n",
    "\n",
    "def check_for_nan(*tensors, names=None):\n",
    "    \"\"\"\n",
    "    Controlla se ci sono NaN o Inf nei tensori\n",
    "    \n",
    "    Args:\n",
    "        *tensors: Tensori da controllare\n",
    "        names: Nomi dei tensori per il debug\n",
    "    \n",
    "    Returns:\n",
    "        bool: True se trovati NaN/Inf\n",
    "    \"\"\"\n",
    "    if names is None:\n",
    "        names = [f\"tensor_{i}\" for i in range(len(tensors))]\n",
    "    \n",
    "    for tensor, name in zip(tensors, names):\n",
    "        if torch.isnan(tensor).any():\n",
    "            print(f\"🚨 NaN detected in {name}\")\n",
    "            return True\n",
    "        if torch.isinf(tensor).any():\n",
    "            print(f\"🚨 Inf detected in {name}\")\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def set_requires_grad(models, requires_grad):\n",
    "    \"\"\"\n",
    "    Abilita/disabilita i gradienti per i modelli\n",
    "    \n",
    "    Args:\n",
    "        models: Modello singolo o lista di modelli\n",
    "        requires_grad: True per abilitare, False per disabilitare\n",
    "    \"\"\"\n",
    "    if not isinstance(models, list):\n",
    "        models = [models]\n",
    "    for model in models:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "\n",
    "\n",
    "def get_learning_rate_multiplier(epoch, warmup_epochs):\n",
    "    \"\"\"\n",
    "    Calcola il moltiplicatore del learning rate per il warmup\n",
    "    \n",
    "    Args:\n",
    "        epoch: Epoca corrente\n",
    "        warmup_epochs: Numero di epoche di warmup\n",
    "    \n",
    "    Returns:\n",
    "        float: Moltiplicatore del learning rate\n",
    "    \"\"\"\n",
    "    if epoch < warmup_epochs:\n",
    "        return (epoch + 1) / warmup_epochs\n",
    "    return 1.0\n",
    "\n",
    "def save_checkpoint(epoch, models_dict, optimizers_dict, schedulers_dict, config):\n",
    "    \"\"\"\n",
    "    Salva checkpoint completo\n",
    "    \n",
    "    Args:\n",
    "        epoch: Epoca corrente\n",
    "        models_dict: Dizionario dei modelli\n",
    "        optimizers_dict: Dizionario degli ottimizzatori\n",
    "        schedulers_dict: Dizionario degli schedulers\n",
    "        config: Configurazione\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'config': config\n",
    "    }\n",
    "    \n",
    "    # Salva stati dei modelli\n",
    "    for name, model in models_dict.items():\n",
    "        checkpoint[name] = model.state_dict()\n",
    "    \n",
    "    # Salva stati degli ottimizzatori\n",
    "    for name, optimizer in optimizers_dict.items():\n",
    "        checkpoint[name] = optimizer.state_dict()\n",
    "    \n",
    "    # Salva stati degli schedulers\n",
    "    for name, scheduler in schedulers_dict.items():\n",
    "        checkpoint[name] = scheduler.state_dict()\n",
    "    \n",
    "    checkpoint_path = os.path.join(config[\"save_dir\"], f\"checkpoint_epoch_{epoch}.pth\")\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"💾 Checkpoint saved: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6491e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models...\n",
      "style_encoder initialized\n",
      "content_encoder initialized\n",
      "discriminator initialized\n",
      "decoder initialized\n"
     ]
    }
   ],
   "source": [
    "# model initialization\n",
    "print(\"Initializing models...\")\n",
    "\n",
    "style_encoder = StyleEncoder(\n",
    "    cnn_out_dim=config[\"style_dim\"],\n",
    "    transformer_dim=config[\"style_dim\"],\n",
    "    num_heads=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"]\n",
    ").to(device)\n",
    "\n",
    "content_encoder = ContentEncoder(\n",
    "    cnn_out_dim=config[\"content_dim\"],\n",
    "    transformer_dim=config[\"content_dim\"],\n",
    "    num_heads=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"],\n",
    "    channels_list=config[\"cnn_channels\"]\n",
    ").to(device)\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    input_dim=config[\"style_dim\"],\n",
    "    hidden_dim=128\n",
    ").to(device)\n",
    "\n",
    "decoder = Decoder(\n",
    "    d_model=config[\"style_dim\"],\n",
    "    nhead=config[\"transformer_heads\"],\n",
    "    num_layers=config[\"transformer_layers\"]\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# Applica inizializzazione conservativa\n",
    "models = [style_encoder, content_encoder, discriminator, decoder]\n",
    "model_names = [\"style_encoder\", \"content_encoder\", \"discriminator\", \"decoder\"]\n",
    "\n",
    "# inizializzazione conservativa\n",
    "for model, name in zip(models, model_names):\n",
    "    model.apply(init_weights_conservative)\n",
    "    print(f\"{name} initialized\")\n",
    "\n",
    "\n",
    "# inizializzazione regolare\n",
    "# from style_encoder import initialize_weights\n",
    "# initialize_weights(style_encoder)\n",
    "# initialize_weights(content_encoder)\n",
    "# initialize_weights(decoder)\n",
    "# initialize_weights(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64392f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Setting up optimizers and schedulers...\n",
      "🔧 Setting up dataloader...\n",
      "✅ Loaded separate statistics:\n",
      "  Piano: train_set_stats/stats_stft_cqt_piano.npz\n",
      "  Violin: train_set_stats/stats_stft_cqt_violin.npz\n",
      "✅ DataLoader created successfully with batch_size=16\n"
     ]
    }
   ],
   "source": [
    "# optimizers and schedulers\n",
    "print(\"🔧 Setting up optimizers and schedulers...\")\n",
    "\n",
    "optimizer_G = optim.AdamW(\n",
    "    list(style_encoder.parameters()) + \n",
    "    list(content_encoder.parameters()) + \n",
    "    list(decoder.parameters()),\n",
    "    lr=config[\"lr_gen\"],\n",
    "    betas=(config[\"beta1\"], config[\"beta2\"]),\n",
    "    weight_decay=config[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "optimizer_D = optim.AdamW(\n",
    "    discriminator.parameters(),\n",
    "    lr=config[\"lr_disc\"],\n",
    "    betas=(config[\"beta1\"], config[\"beta2\"]),\n",
    "    weight_decay=config[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "# Schedulers\n",
    "scheduler_G = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_G, mode='min', factor=0.7, patience=5\n",
    ")\n",
    "\n",
    "scheduler_D = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_D, mode='min', factor=0.7, patience=5\n",
    ")\n",
    "\n",
    "# dataloader\n",
    "print(\"🔧 Setting up dataloader...\")\n",
    "\n",
    "try:\n",
    "    train_loader = get_dataloader(\n",
    "        piano_dir=config[\"piano_dir\"],\n",
    "        violin_dir=config[\"violin_dir\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        stats_path=config[\"stats_path\"]\n",
    "    )\n",
    "    print(f\"✅ DataLoader created successfully with batch_size={config['batch_size']}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating DataLoader: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d068e",
   "metadata": {},
   "source": [
    "## Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10a50400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training steps for discriminator and generator\n",
    "def discriminator_training_step(x, labels, epoch):\n",
    "\n",
    "    # only discriminator requires gradients\n",
    "    # set_requires_grad(discriminator, True)\n",
    "    # set_requires_grad([style_encoder, content_encoder, decoder], False)\n",
    "    \n",
    "    try:\n",
    "        # no gradient flow for generators\n",
    "        with torch.no_grad():\n",
    "            style_emb, class_emb = style_encoder(x, labels)\n",
    "            content_emb = content_encoder(x)\n",
    "        \n",
    "        # NaN check\n",
    "        if check_for_nan(style_emb, class_emb, content_emb, \n",
    "                         names=[\"style_emb\", \"class_emb\", \"content_emb\"]):\n",
    "            return float('nan')\n",
    "        \n",
    "        # detach embeddings to avoid gradient flow\n",
    "        # removed detach\n",
    "        disc_loss, _ = adversarial_loss(\n",
    "            style_emb,\n",
    "            class_emb,\n",
    "            content_emb,\n",
    "            discriminator,\n",
    "            labels,\n",
    "            compute_for_discriminator=True,\n",
    "            lambda_content=config[\"lambda_adv_disc\"]\n",
    "        )\n",
    "        \n",
    "        # NaN\n",
    "        if check_for_nan(disc_loss, names=[\"disc_loss\"]):\n",
    "            return float('nan')\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer_D.zero_grad()\n",
    "        disc_loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(discriminator.parameters(), config[\"grad_clip_value\"])\n",
    "        \n",
    "        # Controllo gradienti per NaN\n",
    "        for name, param in discriminator.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                if check_for_nan(param.grad, names=[f\"discriminator.{name}.grad\"]):\n",
    "                    return float('nan')\n",
    "        \n",
    "        optimizer_D.step()\n",
    "        return disc_loss.item()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in discriminator training step: {e}\")\n",
    "        return float('nan')\n",
    "\n",
    "\n",
    "\n",
    "def generator_training_step(x, labels, epoch):\n",
    "\n",
    "    # set_requires_grad([style_encoder, content_encoder, decoder], True)\n",
    "    # set_requires_grad(discriminator, False)\n",
    "    \n",
    "    try:\n",
    "\n",
    "        style_emb, class_emb = style_encoder(x, labels)\n",
    "        content_emb = content_encoder(x)\n",
    "        \n",
    "\n",
    "        if check_for_nan(style_emb, class_emb, content_emb,\n",
    "                         names=[\"style_emb\", \"class_emb\", \"content_emb\"]):\n",
    "            return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "        \n",
    "\n",
    "        _, adv_gen_loss = adversarial_loss(\n",
    "            style_emb,\n",
    "            class_emb,\n",
    "            content_emb,\n",
    "            discriminator,\n",
    "            labels,\n",
    "            compute_for_discriminator=False,\n",
    "            lambda_content=config[\"lambda_adv_gen\"]\n",
    "        )\n",
    "        \n",
    "        # disentanglement\n",
    "        disent_loss = disentanglement_loss(\n",
    "            style_emb,\n",
    "            content_emb.mean(dim=1),\n",
    "            use_hsic=True\n",
    "        )\n",
    "        \n",
    "        # contrastive losses\n",
    "        cont_loss = infoNCE_loss(style_emb, labels)\n",
    "        \n",
    "        margin_loss_val = margin_loss(class_emb)\n",
    "        \n",
    "        # reconstruction loss\n",
    "        # get only stft from input\n",
    "        stft_part = x[:, :, :, :, :513]\n",
    "\n",
    "        # duplicate class embedding from (2,d) to (B,d)\n",
    "        B = content_emb.size(0)\n",
    "        class_emb = class_emb.repeat_interleave(repeats=B//2, dim=0)\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_x = decoder(content_emb, class_emb, y=stft_part)\n",
    "        recon_losses = compute_comprehensive_loss(recon_x, stft_part)\n",
    "        recon_loss = recon_losses['total_loss']\n",
    "        \n",
    "        # NaN\n",
    "        losses = [adv_gen_loss, disent_loss, cont_loss, margin_loss_val, recon_loss]\n",
    "        loss_names = ['adv_gen_loss', 'disent_loss', 'cont_loss', 'margin_loss', 'recon_loss']\n",
    "        \n",
    "        if check_for_nan(*losses, names=loss_names):\n",
    "            return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "        \n",
    "        # total loss with warmup\n",
    "        lr_multiplier = get_learning_rate_multiplier(epoch, config[\"warmup_epochs\"])\n",
    "        warmup_factor = lr_multiplier if epoch < config[\"warmup_epochs\"] else 1.0\n",
    "        \n",
    "        total_G_loss = (\n",
    "            config[\"lambda_adv_gen\"] * adv_gen_loss * warmup_factor +\n",
    "            config[\"lambda_disent\"] * disent_loss * warmup_factor +\n",
    "            config[\"lambda_cont\"] * cont_loss * warmup_factor +\n",
    "            config[\"lambda_margin\"] * margin_loss_val * warmup_factor +\n",
    "            config[\"lambda_recon\"] * recon_loss\n",
    "        )\n",
    "        \n",
    "        if check_for_nan(total_G_loss, names=[\"total_G_loss\"]):\n",
    "            return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer_G.zero_grad()\n",
    "        total_G_loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        generator_params = (\n",
    "            list(style_encoder.parameters()) + \n",
    "            list(content_encoder.parameters()) +\n",
    "            list(decoder.parameters())\n",
    "        )\n",
    "        torch.nn.utils.clip_grad_norm_(generator_params, config[\"grad_clip_value\"])\n",
    "        \n",
    "        # NaN\n",
    "        for model, model_name in [(style_encoder, \"style_encoder\"), \n",
    "                                 (content_encoder, \"content_encoder\"), \n",
    "                                 (decoder, \"decoder\")]:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    if check_for_nan(param.grad, names=[f\"{model_name}.{name}.grad\"]):\n",
    "                        return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        \n",
    "        return {\n",
    "            'total_G': total_G_loss.item(),\n",
    "            'adv_gen': adv_gen_loss.item(),\n",
    "            'disent': disent_loss.item(),\n",
    "            'cont': cont_loss.item(),\n",
    "            'margin': margin_loss_val.item(),\n",
    "            'recon': recon_loss.item()\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in generator training step: {e}\")\n",
    "        return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef9ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting training with enhanced NaN protection...\n",
      "📊 Configuration: {'style_dim': 256, 'content_dim': 256, 'transformer_heads': 4, 'transformer_layers': 4, 'cnn_channels': [16, 32, 64, 128, 256], 'epochs': 100, 'batch_size': 16, 'lr_gen': 3e-05, 'lr_disc': 1e-05, 'beta1': 0.5, 'beta2': 0.999, 'weight_decay': 0.0001, 'lambda_adv_disc': 1.0, 'lambda_adv_gen': 0.5, 'lambda_disent': 1.0, 'lambda_cont': 0.5, 'lambda_margin': 0.5, 'lambda_recon': 5.0, 'grad_clip_value': 0.5, 'warmup_epochs': 5, 'nan_threshold': 5, 'piano_dir': 'dataset/train/piano', 'violin_dir': 'dataset/train/violin', 'stats_path': 'stats_stft_cqt.npz', 'save_dir': 'checkpoints', 'save_interval': 10, 'discriminator_steps': 3, 'generator_steps': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Epoch 1/100\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Batch 1:\n",
      "   Generator Total Loss: 13.676488\n",
      "     Adv Gen: -0.346590\n",
      "     Disent: 0.000856\n",
      "     Cont: 2.709802\n",
      "     Margin: 0.085060\n",
      "     Recon: 2.686298\n",
      "   Consecutive NaN count: 0\n",
      "\n",
      "📊 Batch 2:\n",
      "   Generator Total Loss: 14.303087\n",
      "     Adv Gen: -0.346758\n",
      "     Disent: 0.001143\n",
      "     Cont: 2.708168\n",
      "     Margin: 0.047283\n",
      "     Recon: 2.812398\n",
      "   Consecutive NaN count: 0\n"
     ]
    }
   ],
   "source": [
    "# main train loop\n",
    "print(\"🚀 Starting training with enhanced NaN protection...\")\n",
    "print(f\"📊 Configuration: {config}\")\n",
    "\n",
    "\n",
    "loss_history = {\n",
    "    'total_G': [],\n",
    "    'disc': [],\n",
    "    'disent': [],\n",
    "    'cont': [],\n",
    "    'margin': [],\n",
    "    'recon': [],\n",
    "    'adv_gen': []\n",
    "}\n",
    "\n",
    "\n",
    "consecutive_nan_count = 0\n",
    "max_consecutive_nans = config[\"nan_threshold\"]\n",
    "\n",
    "\n",
    "models_dict = {\n",
    "    'style_encoder': style_encoder,\n",
    "    'content_encoder': content_encoder,\n",
    "    'discriminator': discriminator,\n",
    "    'decoder': decoder\n",
    "}\n",
    "\n",
    "optimizers_dict = {\n",
    "    'optimizer_G': optimizer_G,\n",
    "    'optimizer_D': optimizer_D\n",
    "}\n",
    "\n",
    "schedulers_dict = {\n",
    "    'scheduler_G': scheduler_G,\n",
    "    'scheduler_D': scheduler_D\n",
    "}\n",
    "\n",
    "try:\n",
    "    for epoch in tqdm(range(config[\"epochs\"]), desc=\"Training Progress\"):\n",
    "        # early stopping check for NaN\n",
    "        if consecutive_nan_count >= max_consecutive_nans:\n",
    "            print(f\"🛑 Early stopping: {consecutive_nan_count} consecutive NaN occurrences\")\n",
    "            break\n",
    "        \n",
    "        # set all models to training mode\n",
    "        for model in models:\n",
    "            model.train()\n",
    "        \n",
    "        epoch_losses = {key: [] for key in loss_history.keys()}\n",
    "        \n",
    "        print(f\"\\n🔄 Epoch {epoch+1}/{config['epochs']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        generator_steps = config[\"generator_steps\"]\n",
    "        disc_steps = config[\"discriminator_steps\"]\n",
    "            \n",
    "        # to compute when to train generator and discriminator\n",
    "        cycle_length = generator_steps + disc_steps\n",
    "        \n",
    "        for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            x = x.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Controllo NaN nei dati di input\n",
    "            if check_for_nan(x, labels, names=[\"input_x\", \"input_labels\"]):\n",
    "                print(f\"⚠️  Skipping batch {batch_idx} due to NaN in input data\")\n",
    "                continue\n",
    "            \n",
    "            # to compute turns in the cycle\n",
    "            step_in_cycle = batch_idx % cycle_length\n",
    "            \n",
    "            \n",
    "            # ============================================\n",
    "            # GENERATORS training\n",
    "            # ============================================\n",
    "            if step_in_cycle < generator_steps:\n",
    "                gen_losses = generator_training_step(x, labels, epoch)\n",
    "                \n",
    "                # NaN\n",
    "                nan_in_gen = any(np.isnan(v) for v in gen_losses.values())\n",
    "                \n",
    "                if not nan_in_gen:\n",
    "                    for key, value in gen_losses.items():\n",
    "                        if key in epoch_losses:\n",
    "                            epoch_losses[key].append(value)\n",
    "                    consecutive_nan_count = 0  # Reset counter su successo\n",
    "                else:\n",
    "                    consecutive_nan_count += 1\n",
    "                    print(f\"⚠️  NaN in generator losses (consecutive: {consecutive_nan_count})\")           \n",
    "            \n",
    "            \n",
    "            \n",
    "            # ============================================\n",
    "            # DISCRIMINATOR training\n",
    "            # ============================================\n",
    "            else:\n",
    "                disc_loss = discriminator_training_step(x, labels, epoch)\n",
    "                \n",
    "                # NaN\n",
    "                if not np.isnan(disc_loss):\n",
    "                    epoch_losses['disc'].append(disc_loss)\n",
    "                    consecutive_nan_count = 0  # Reset counter \n",
    "                else:\n",
    "                    consecutive_nan_count += 1\n",
    "                    print(f\"⚠️  NaN in discriminator loss (consecutive: {consecutive_nan_count})\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # ============================================\n",
    "            # Batch Logging\n",
    "            # ============================================\n",
    "            if batch_idx % 1 == 0:\n",
    "                print(f\"\\n📊 Batch {batch_idx + 1}:\")\n",
    "                \n",
    "                # disc loss\n",
    "                if epoch_losses['disc']:\n",
    "                    recent_disc = epoch_losses['disc'][-config[\"discriminator_steps\"]:]\n",
    "                    avg_disc = np.mean(recent_disc)\n",
    "                    print(f\"   Discriminator Loss: {avg_disc:.6f}\")\n",
    "                \n",
    "                # gen loss\n",
    "                if epoch_losses['total_G']:\n",
    "                    recent_gen = epoch_losses['total_G'][-config[\"generator_steps\"]:]\n",
    "                    avg_total_G = np.mean(recent_gen)\n",
    "                    print(f\"   Generator Total Loss: {avg_total_G:.6f}\")\n",
    "                \n",
    "                # individual losses\n",
    "                gen_loss_names = ['adv_gen', 'disent', 'cont', 'margin', 'recon']\n",
    "                for loss_name in gen_loss_names:\n",
    "                    if epoch_losses[loss_name]:\n",
    "                        recent_loss = epoch_losses[loss_name][-config[\"generator_steps\"]:]\n",
    "                        avg_loss = np.mean(recent_loss)\n",
    "                        print(f\"     {loss_name.replace('_', ' ').title()}: {avg_loss:.6f}\")\n",
    "                \n",
    "\n",
    "                print(f\"   Consecutive NaN count: {consecutive_nan_count}\")\n",
    "                if torch.cuda.is_available():\n",
    "                    print(f\"   GPU Memory: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")\n",
    "            \n",
    "            # NaN\n",
    "            if consecutive_nan_count >= max_consecutive_nans:\n",
    "                print(f\"🛑 Stopping epoch {epoch+1} due to consecutive NaN issues\")\n",
    "                break\n",
    "        \n",
    "        # ============================================\n",
    "        # update and save\n",
    "        # ============================================\n",
    "        if consecutive_nan_count < max_consecutive_nans:\n",
    "            # update schedulers\n",
    "            if epoch_losses['disc']:\n",
    "                scheduler_D.step(np.mean(epoch_losses['disc']))\n",
    "            if epoch_losses['total_G']:\n",
    "                scheduler_G.step(np.mean(epoch_losses['total_G']))\n",
    "            \n",
    "            # add loss\n",
    "            for key in loss_history.keys():\n",
    "                if epoch_losses[key]:\n",
    "                    loss_history[key].extend(epoch_losses[key])\n",
    "            \n",
    "            # save checkpoint\n",
    "            if (epoch + 1) % config[\"save_interval\"] == 0:\n",
    "                save_checkpoint(epoch + 1, models_dict, optimizers_dict, schedulers_dict, config)\n",
    "            \n",
    "            # epoch summary\n",
    "            print(f\"\\n✅ Epoch {epoch+1} Summary:\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            for key in ['disc', 'total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']:\n",
    "                if epoch_losses[key]:\n",
    "                    avg_loss = np.mean(epoch_losses[key])\n",
    "                    print(f\"   {key.replace('_', ' ').title()}: {avg_loss:.6f}\")\n",
    "            \n",
    "            current_lr_G = optimizer_G.param_groups[0]['lr']\n",
    "            current_lr_D = optimizer_D.param_groups[0]['lr']\n",
    "            print(f\"   LR Generator: {current_lr_G:.2e}\")\n",
    "            print(f\"   LR Discriminator: {current_lr_D:.2e}\")\n",
    "            \n",
    "            print(\"-\" * 60)\n",
    "        \n",
    "        # memory clean\n",
    "        if torch.cuda.is_available() and epoch % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n⏹️  Training interrupted by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Training error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    # final save\n",
    "    print(\"\\n💾 Saving final checkpoint...\")\n",
    "    save_checkpoint(epoch + 1, models_dict, optimizers_dict, schedulers_dict, config)\n",
    "    \n",
    "    # Visualizzazione delle loss\n",
    "    if any(loss_history[key] for key in loss_history.keys()):\n",
    "        print(\"📊 Generating loss plots...\")\n",
    "        \n",
    "        # Configura plot\n",
    "        plt.style.use('default')\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Definisci le loss da plottare\n",
    "        loss_configs = [\n",
    "            ('disc', 'Discriminator Loss', 'red'),\n",
    "            ('total_G', 'Generator Total Loss', 'blue'),\n",
    "            ('recon', 'Reconstruction Loss', 'green'),\n",
    "            ('adv_gen', 'Adversarial Generator Loss', 'orange'),\n",
    "            ('disent', 'Disentanglement Loss', 'purple'),\n",
    "            ('cont', 'Contrastive Loss', 'brown')\n",
    "        ]\n",
    "        \n",
    "        for i, (loss_name, title, color) in enumerate(loss_configs):\n",
    "            if loss_history[loss_name]:\n",
    "                values = loss_history[loss_name]\n",
    "                \n",
    "                # Plot raw values\n",
    "                axes[i].plot(values, alpha=0.4, color=color, linewidth=0.5, label='Raw')\n",
    "                \n",
    "                # Plot smoothed values se ci sono abbastanza punti\n",
    "                if len(values) > 50:\n",
    "                    window = max(1, len(values) // 50)\n",
    "                    smoothed = np.convolve(values, np.ones(window)/window, mode='valid')\n",
    "                    axes[i].plot(smoothed, color=color, linewidth=2, label='Smoothed')\n",
    "                \n",
    "                axes[i].set_title(title, fontsize=12, fontweight='bold')\n",
    "                axes[i].set_xlabel('Iteration')\n",
    "                axes[i].set_ylabel('Loss')\n",
    "                axes[i].legend()\n",
    "                axes[i].grid(True, alpha=0.3)\n",
    "                axes[i].set_xlim(0, len(values))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plot_path = os.path.join(config[\"save_dir\"], \"loss_curves.png\")\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"📈 Loss curves saved to: {plot_path}\")\n",
    "    \n",
    "    # Riepilogo finale\n",
    "    print(f\"\\n🎯 Training completed!\")\n",
    "    print(f\"   Total epochs processed: {epoch + 1}\")\n",
    "    print(f\"   Final consecutive NaN count: {consecutive_nan_count}\")\n",
    "    print(f\"   Checkpoints saved in: {config['save_dir']}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   Final GPU memory: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")\n",
    "    \n",
    "    print(\"🎉 Training session finished successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9463e51",
   "metadata": {},
   "source": [
    "## Train with curriculum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b25b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_curriculum_weights(epoch, total_epochs):\n",
    "    progress = epoch / total_epochs\n",
    "    \n",
    "    # phase 1 (0-20%): only reconstruction\n",
    "    if progress < 0.2:\n",
    "        return {\n",
    "            \"lambda_recon\": 10.0,\n",
    "            \"lambda_adv_gen\": 0.0,\n",
    "            \"lambda_adv_disc\": 0.0,\n",
    "            \"lambda_disent\": 0.0,\n",
    "            \"lambda_cont\": 0.0,\n",
    "            \"lambda_margin\": 0.0\n",
    "        }\n",
    "    \n",
    "    # phase 2 (20-40%): add contrastive\n",
    "    elif progress < 0.4:\n",
    "        return {\n",
    "            \"lambda_recon\": 8.0,\n",
    "            \"lambda_adv_gen\": 0.0,\n",
    "            \"lambda_adv_disc\": 0.0,\n",
    "            \"lambda_disent\": 0.0,\n",
    "            \"lambda_cont\": 0.5,\n",
    "            \"lambda_margin\": 0.5\n",
    "        }\n",
    "    \n",
    "    # phase 2 (40-60%): add disentanglement\n",
    "    elif progress < 0.6:\n",
    "        return {\n",
    "            \"lambda_recon\": 5.0,\n",
    "            \"lambda_adv_gen\": 0.0,\n",
    "            \"lambda_adv_disc\": 0.0,\n",
    "            \"lambda_disent\": 0.5,\n",
    "            \"lambda_cont\": 0.8,\n",
    "            \"lambda_margin\": 1\n",
    "        }\n",
    "    \n",
    "    # phase 4 (60-100%): introduce adversarial training gradually\n",
    "    else:\n",
    "        # gradual increase of adversarial loss\n",
    "        adv_strength = min(1.0, (progress - 0.6) / 0.4)\n",
    "        return {\n",
    "            \"lambda_recon\": 3.0,\n",
    "            \"lambda_adv_gen\": 0.5 * adv_strength,\n",
    "            \"lambda_adv_disc\": 0.3 * adv_strength,\n",
    "            \"lambda_disent\": 0.3,\n",
    "            \"lambda_cont\": 0.8,\n",
    "            \"lambda_margin\": 1\n",
    "        }\n",
    "    \n",
    "\n",
    "def display_final_loss_summary(loss_history, config):\n",
    "    \"\"\"\n",
    "    Visualizza il riepilogo finale delle loss e genera i grafici\n",
    "    \"\"\"\n",
    "    print(\"📊 Generating final loss summary and plots...\")\n",
    "    \n",
    "    # Controlla se ci sono loss da visualizzare\n",
    "    if not any(loss_history[key] for key in loss_history.keys()):\n",
    "        print(\"⚠️  No loss data to display\")\n",
    "        return\n",
    "    \n",
    "    # Configura plot\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Definisci le loss da plottare\n",
    "    loss_configs = [\n",
    "        ('disc', 'Discriminator Loss', 'red'),\n",
    "        ('total_G', 'Generator Total Loss', 'blue'),\n",
    "        ('recon', 'Reconstruction Loss', 'green'),\n",
    "        ('adv_gen', 'Adversarial Generator Loss', 'orange'),\n",
    "        ('disent', 'Disentanglement Loss', 'purple'),\n",
    "        ('cont', 'Contrastive Loss', 'brown')\n",
    "    ]\n",
    "    \n",
    "    for i, (loss_name, title, color) in enumerate(loss_configs):\n",
    "        if loss_history[loss_name]:\n",
    "            values = loss_history[loss_name]\n",
    "            \n",
    "            # Plot raw values\n",
    "            axes[i].plot(values, alpha=0.4, color=color, linewidth=0.5, label='Raw')\n",
    "            \n",
    "            # Plot smoothed values se ci sono abbastanza punti\n",
    "            if len(values) > 50:\n",
    "                window = max(1, len(values) // 50)\n",
    "                smoothed = np.convolve(values, np.ones(window)/window, mode='valid')\n",
    "                axes[i].plot(smoothed, color=color, linewidth=2, label='Smoothed')\n",
    "            \n",
    "            axes[i].set_title(title, fontsize=12, fontweight='bold')\n",
    "            axes[i].set_xlabel('Iteration')\n",
    "            axes[i].set_ylabel('Loss')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            axes[i].set_xlim(0, len(values))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(config[\"save_dir\"], \"curriculum_loss_curves.png\")\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"📈 Loss curves saved to: {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbecc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_training_step_curriculum(x, labels, epoch, total_epochs):\n",
    "    \"\"\"\n",
    "    Step di training per il discriminatore con curriculum learning\n",
    "    \"\"\"\n",
    "    # Ottieni pesi curriculum\n",
    "    curriculum_weights = get_curriculum_weights(epoch, total_epochs)\n",
    "    \n",
    "    # Salta training del discriminatore se non è ancora attivo\n",
    "    if curriculum_weights[\"lambda_adv_disc\"] == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Abilita gradienti solo per discriminatore\n",
    "    # set_requires_grad(discriminator, True)\n",
    "    # set_requires_grad([style_encoder, content_encoder, decoder], False)\n",
    "    \n",
    "    try:\n",
    "        # Forward pass senza gradienti per i generatori\n",
    "        with torch.no_grad():\n",
    "            style_emb, class_emb = style_encoder(x, labels)\n",
    "            content_emb = content_encoder(x)\n",
    "        \n",
    "        # Controllo NaN negli embeddings\n",
    "        if check_for_nan(style_emb, class_emb, content_emb, \n",
    "                         names=[\"style_emb\", \"class_emb\", \"content_emb\"]):\n",
    "            return float('nan')\n",
    "        \n",
    "        # Calcola loss del discriminatore\n",
    "        # removed detach from style,class,content embeddings\n",
    "        disc_loss, _ = adversarial_loss(\n",
    "            style_emb,\n",
    "            class_emb,\n",
    "            content_emb,\n",
    "            discriminator,\n",
    "            labels,\n",
    "            compute_for_discriminator=True,\n",
    "            lambda_content=curriculum_weights[\"lambda_adv_disc\"]\n",
    "        )\n",
    "        \n",
    "        # Controllo NaN nella loss\n",
    "        if check_for_nan(disc_loss, names=[\"disc_loss\"]):\n",
    "            return float('nan')\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer_D.zero_grad()\n",
    "        disc_loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(discriminator.parameters(), config[\"grad_clip_value\"])\n",
    "        \n",
    "        optimizer_D.step()\n",
    "        \n",
    "        return disc_loss.item()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in discriminator training step: {e}\")\n",
    "        return float('nan')\n",
    "\n",
    "\n",
    "\n",
    "def generator_training_step_curriculum(x, labels, epoch, total_epochs):\n",
    "    \"\"\"\n",
    "    Step di training per i generatori con curriculum learning\n",
    "    \"\"\"\n",
    "    # Ottieni pesi curriculum per l'epoca corrente\n",
    "    curriculum_weights = get_curriculum_weights(epoch, total_epochs)\n",
    "    \n",
    "    # Abilita gradienti per i generatori\n",
    "    # set_requires_grad([style_encoder, content_encoder, decoder], True)\n",
    "    # set_requires_grad(discriminator, False)\n",
    "    \n",
    "    try:\n",
    "        # Forward pass\n",
    "        style_emb, class_emb = style_encoder(x, labels)\n",
    "        content_emb = content_encoder(x)\n",
    "        \n",
    "        # Controllo NaN\n",
    "        if check_for_nan(style_emb, class_emb, content_emb,\n",
    "                         names=[\"style_emb\", \"class_emb\", \"content_emb\"]):\n",
    "            return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "        \n",
    "        # Calcola solo le loss attive nel curriculum\n",
    "        losses = {}\n",
    "        \n",
    "        # Loss di ricostruzione (sempre attiva)\n",
    "        if curriculum_weights[\"lambda_recon\"] > 0:\n",
    "            \n",
    "            stft_part = x[:, :, :, :, :513]\n",
    "            class_emb = class_emb.repeat_interleave(repeats=stft_part.size(0) // 2, dim=0)\n",
    "            \n",
    "            recon_x = decoder(content_emb, class_emb, y=stft_part)\n",
    "            recon_losses = compute_comprehensive_loss(recon_x, stft_part)\n",
    "            losses[\"recon\"] = recon_losses['total_loss']\n",
    "        \n",
    "        # Loss di disentanglement\n",
    "        if curriculum_weights[\"lambda_disent\"] > 0:\n",
    "            losses[\"disent\"] = disentanglement_loss(\n",
    "                style_emb, content_emb.mean(dim=1), use_hsic=True\n",
    "            )\n",
    "        \n",
    "        # Loss contrastiva\n",
    "        if curriculum_weights[\"lambda_cont\"] > 0:\n",
    "            losses[\"cont\"] = infoNCE_loss(style_emb, labels)\n",
    "        \n",
    "        # Margin loss\n",
    "        if curriculum_weights[\"lambda_margin\"] > 0:\n",
    "            losses[\"margin\"] = margin_loss(class_emb)\n",
    "        \n",
    "        # Adversarial loss (solo quando attivata)\n",
    "        if curriculum_weights[\"lambda_adv_gen\"] > 0:\n",
    "            _, losses[\"adv_gen\"] = adversarial_loss(\n",
    "                style_emb, class_emb, content_emb, discriminator, labels,\n",
    "                compute_for_discriminator=False,\n",
    "                lambda_content=curriculum_weights[\"lambda_adv_gen\"]\n",
    "            )\n",
    "        \n",
    "        # Controlla NaN in tutte le loss calcolate\n",
    "        if check_for_nan(*losses.values(), names=list(losses.keys())):\n",
    "            return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}\n",
    "        \n",
    "        # Calcola loss totale usando i pesi del curriculum\n",
    "        total_G_loss = sum(\n",
    "            curriculum_weights[f\"lambda_{key}\"] * loss_val\n",
    "            for key, loss_val in losses.items()\n",
    "            if f\"lambda_{key}\" in curriculum_weights\n",
    "        )\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer_G.zero_grad()\n",
    "        total_G_loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        generator_params = (\n",
    "            list(style_encoder.parameters()) + \n",
    "            list(content_encoder.parameters()) +\n",
    "            list(decoder.parameters())\n",
    "        )\n",
    "        torch.nn.utils.clip_grad_norm_(generator_params, config[\"grad_clip_value\"])\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Prepara output con tutte le loss (0 se non attive)\n",
    "        output_losses = {\n",
    "            'total_G': total_G_loss.item(),\n",
    "            'recon': losses.get(\"recon\", torch.tensor(0.0)).item(),\n",
    "            'disent': losses.get(\"disent\", torch.tensor(0.0)).item(),\n",
    "            'cont': losses.get(\"cont\", torch.tensor(0.0)).item(),\n",
    "            'margin': losses.get(\"margin\", torch.tensor(0.0)).item(),\n",
    "            'adv_gen': losses.get(\"adv_gen\", torch.tensor(0.0)).item()\n",
    "        }\n",
    "        \n",
    "        return output_losses\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in generator training step: {e}\")\n",
    "        return {key: float('nan') for key in ['total_G', 'adv_gen', 'disent', 'cont', 'margin', 'recon']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_curriculum():\n",
    "    \"\"\"\n",
    "    Training principale con curriculum learning integrato\n",
    "    \"\"\"\n",
    "    print(\"🚀 Starting curriculum learning training...\")\n",
    "    \n",
    "    # Inizializza strutture per il tracking delle loss\n",
    "    loss_history = {\n",
    "        'total_G': [],\n",
    "        'disc': [],\n",
    "        'disent': [],\n",
    "        'cont': [],\n",
    "        'margin': [],\n",
    "        'recon': [],\n",
    "        'adv_gen': []\n",
    "    }\n",
    "    \n",
    "    # Contatore per NaN consecutivi\n",
    "    consecutive_nan_count = 0\n",
    "    max_consecutive_nans = config[\"nan_threshold\"]\n",
    "    \n",
    "    # Dizionari per salvataggio\n",
    "    models_dict = {\n",
    "        'style_encoder': style_encoder,\n",
    "        'content_encoder': content_encoder,\n",
    "        'discriminator': discriminator,\n",
    "        'decoder': decoder\n",
    "    }\n",
    "    \n",
    "    optimizers_dict = {\n",
    "        'optimizer_G': optimizer_G,\n",
    "        'optimizer_D': optimizer_D\n",
    "    }\n",
    "    \n",
    "    schedulers_dict = {\n",
    "        'scheduler_G': scheduler_G,\n",
    "        'scheduler_D': scheduler_D\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        for epoch in tqdm(range(config[\"epochs\"]), desc=\"Curriculum Training\"):\n",
    "            # Controllo early stopping per NaN\n",
    "            if consecutive_nan_count >= max_consecutive_nans:\n",
    "                print(f\"🛑 Early stopping: {consecutive_nan_count} consecutive NaN occurrences\")\n",
    "                break\n",
    "            \n",
    "            # Ottieni pesi curriculum per l'epoca corrente\n",
    "            curriculum_weights = get_curriculum_weights(epoch, config[\"epochs\"])\n",
    "            \n",
    "            # Imposta tutti i modelli in modalità training\n",
    "            for model in models:\n",
    "                model.train()\n",
    "            \n",
    "            # Tracking delle loss per l'epoca corrente\n",
    "            epoch_losses = {key: [] for key in loss_history.keys()}\n",
    "            \n",
    "            # Stampa fase corrente del curriculum\n",
    "            progress = epoch / config[\"epochs\"]\n",
    "            if progress < 0.2:\n",
    "                phase = \"Fase 1: Solo Ricostruzione\"\n",
    "            elif progress < 0.4:\n",
    "                phase = \"Fase 2: + Disentanglement\"\n",
    "            elif progress < 0.6:\n",
    "                phase = \"Fase 3: + Contrastive Learning\"\n",
    "            else:\n",
    "                phase = \"Fase 4: + Adversarial Training\"\n",
    "            \n",
    "            print(f\"\\n🔄 Epoch {epoch+1}/{config['epochs']} - {phase}\")\n",
    "            print(f\"📊 Curriculum weights: {curriculum_weights}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            generator_steps = config[\"generator_steps\"]\n",
    "            disc_steps = config[\"discriminator_steps\"]\n",
    "            \n",
    "            # to compute when to train generator and discriminator\n",
    "            cycle_length = generator_steps + disc_steps\n",
    "            \n",
    "            for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "                # Trasferisce dati su GPU\n",
    "                x = x.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Controllo NaN nei dati di input\n",
    "                if check_for_nan(x, labels, names=[\"input_x\", \"input_labels\"]):\n",
    "                    print(f\"⚠️  Skipping batch {batch_idx} due to NaN in input data\")\n",
    "                    continue\n",
    "                \n",
    "                # to compute turns in the cycle\n",
    "                step_in_cycle = batch_idx % cycle_length\n",
    "                \n",
    "                # ============================================\n",
    "                # TRAINING GENERATORE\n",
    "                # ============================================\n",
    "                if step_in_cycle < generator_steps:\n",
    "                    gen_losses = generator_training_step_curriculum(x, labels, epoch, config[\"epochs\"])\n",
    "                    \n",
    "                    # Controlla se ci sono NaN nelle loss del generatore\n",
    "                    nan_in_gen = any(np.isnan(v) for v in gen_losses.values())\n",
    "                    \n",
    "                    if not nan_in_gen:\n",
    "                        # Aggiungi loss valide alla storia\n",
    "                        for key, value in gen_losses.items():\n",
    "                            if key in epoch_losses:\n",
    "                                epoch_losses[key].append(value)\n",
    "                        consecutive_nan_count = 0\n",
    "                    else:\n",
    "                        consecutive_nan_count += 1\n",
    "                        print(f\"⚠️  NaN in generator losses (consecutive: {consecutive_nan_count})\")\n",
    "                        \n",
    "                \n",
    "                # ============================================\n",
    "                # TRAINING DISCRIMINATORE (solo se attivo)\n",
    "                # ============================================\n",
    "                else:\n",
    "                    if curriculum_weights[\"lambda_adv_disc\"] > 0:\n",
    "                        disc_loss = discriminator_training_step_curriculum(x, labels, epoch, config[\"epochs\"])\n",
    "                            \n",
    "                        if not np.isnan(disc_loss):\n",
    "                            epoch_losses['disc'].append(disc_loss)\n",
    "                            consecutive_nan_count = 0\n",
    "                        else:\n",
    "                            consecutive_nan_count += 1\n",
    "                            print(f\"⚠️  NaN in discriminator loss (consecutive: {consecutive_nan_count})\")\n",
    "                \n",
    "\n",
    "                \n",
    "                # ============================================\n",
    "                # LOGGING PER BATCH\n",
    "                # ============================================\n",
    "                if batch_idx % 10 == 0:\n",
    "                    print(f\"\\n📊 Batch {batch_idx + 1} / {len(train_loader)}:\")\n",
    "                    \n",
    "                    # Solo loss attive nel curriculum\n",
    "                    if curriculum_weights[\"lambda_adv_disc\"] > 0 and epoch_losses['disc']:\n",
    "                        recent_disc = epoch_losses['disc'][-config[\"discriminator_steps\"]:]\n",
    "                        avg_disc = np.mean(recent_disc)\n",
    "                        print(f\"   Discriminator Loss: {avg_disc:.6f}\")\n",
    "                    \n",
    "                    if epoch_losses['total_G']:\n",
    "                        recent_gen = epoch_losses['total_G'][-config[\"generator_steps\"]:]\n",
    "                        avg_total_G = np.mean(recent_gen)\n",
    "                        print(f\"   Generator Total Loss: {avg_total_G:.6f}\")\n",
    "                    \n",
    "                    # Loss individuali attive\n",
    "                    for loss_name, weight_key in [\n",
    "                        ('recon', 'lambda_recon'),\n",
    "                        ('disent', 'lambda_disent'),\n",
    "                        ('cont', 'lambda_cont'),\n",
    "                        ('margin', 'lambda_margin'),\n",
    "                        ('adv_gen', 'lambda_adv_gen')\n",
    "                    ]:\n",
    "                        if curriculum_weights[weight_key] > 0 and epoch_losses[loss_name]:\n",
    "                            recent_loss = epoch_losses[loss_name][-config[\"generator_steps\"]:]\n",
    "                            avg_loss = np.mean(recent_loss)\n",
    "                            print(f\"     {loss_name.replace('_', ' ').title()}: {avg_loss:.6f}\")\n",
    "                \n",
    "                # Controllo early stopping durante il batch\n",
    "                if consecutive_nan_count >= max_consecutive_nans:\n",
    "                    print(f\"🛑 Stopping epoch {epoch+1} due to consecutive NaN issues\")\n",
    "                    break\n",
    "            \n",
    "            # ============================================\n",
    "            # FINE EPOCA: AGGIORNAMENTI E SALVATAGGIO\n",
    "            # ============================================\n",
    "            if consecutive_nan_count < max_consecutive_nans:\n",
    "                # Aggiorna schedulers\n",
    "                if epoch_losses['disc']:\n",
    "                    scheduler_D.step(np.mean(epoch_losses['disc']))\n",
    "                if epoch_losses['total_G']:\n",
    "                    scheduler_G.step(np.mean(epoch_losses['total_G']))\n",
    "                \n",
    "                # Aggiungi loss dell'epoca alla storia globale\n",
    "                for key in loss_history.keys():\n",
    "                    if epoch_losses[key]:\n",
    "                        loss_history[key].extend(epoch_losses[key])\n",
    "                \n",
    "                # Salva checkpoint periodicamente\n",
    "                if (epoch + 1) % config[\"save_interval\"] == 0:\n",
    "                    save_checkpoint(epoch + 1, models_dict, optimizers_dict, schedulers_dict, config)\n",
    "                \n",
    "                # Riepilogo dell'epoca\n",
    "                print(f\"\\n✅ Epoch {epoch+1} Summary:\")\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "                # Mostra solo loss attive\n",
    "                for key, weight_key in [\n",
    "                    ('disc', 'lambda_adv_disc'),\n",
    "                    ('total_G', None),\n",
    "                    ('recon', 'lambda_recon'),\n",
    "                    ('disent', 'lambda_disent'),\n",
    "                    ('cont', 'lambda_cont'),\n",
    "                    ('margin', 'lambda_margin'),\n",
    "                    ('adv_gen', 'lambda_adv_gen')\n",
    "                ]:\n",
    "                    if (weight_key is None or curriculum_weights[weight_key] > 0) and epoch_losses[key]:\n",
    "                        avg_loss = np.mean(epoch_losses[key])\n",
    "                        print(f\"   {key.replace('_', ' ').title()}: {avg_loss:.6f}\")\n",
    "                \n",
    "                print(\"-\" * 60)\n",
    "            \n",
    "            # Pulizia memoria periodica\n",
    "            if torch.cuda.is_available() and epoch % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n⏹️  Training interrupted by user\")\n",
    "        print(\"\\n💾 Saving final checkpoint...\")\n",
    "        save_checkpoint(epoch + 1, models_dict, optimizers_dict, schedulers_dict, config)\n",
    "        \n",
    "        display_final_loss_summary(loss_history, config)\n",
    "        print(f\"   Checkpoints saved in: {config['save_dir']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Training error: {e}\")\n",
    "        print(\"\\n💾 Saving final checkpoint...\")\n",
    "        save_checkpoint(epoch + 1, models_dict, optimizers_dict, schedulers_dict, config)\n",
    "        \n",
    "        display_final_loss_summary(loss_history, config)\n",
    "        print(f\"   Checkpoints saved in: {config['save_dir']}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        # Salvataggio finale\n",
    "        print(\"\\n💾 Saving final checkpoint...\")\n",
    "        save_checkpoint(epoch + 1, models_dict, optimizers_dict, schedulers_dict, config)\n",
    "        \n",
    "        display_final_loss_summary(loss_history, config)\n",
    "        print(f\"   Checkpoints saved in: {config['save_dir']}\")\n",
    "        print(\"🎉 Curriculum learning training completed!\")\n",
    "\n",
    "        for loss_name in ['disc', 'total_G', 'recon', 'adv_gen', 'disent', 'cont', 'margin']:\n",
    "            if loss_history[loss_name]:\n",
    "                values = loss_history[loss_name]\n",
    "                final_avg = np.mean(values[-100:]) if len(values) >= 100 else np.mean(values)\n",
    "                overall_avg = np.mean(values)\n",
    "                min_val = np.min(values)\n",
    "                max_val = np.max(values)\n",
    "                \n",
    "                print(f\"   {loss_name.replace('_', ' ').title()}:\")\n",
    "                print(f\"     Final Average (last 100): {final_avg:.6f}\")\n",
    "                print(f\"     Overall Average: {overall_avg:.6f}\")\n",
    "                print(f\"     Min: {min_val:.6f}, Max: {max_val:.6f}\")\n",
    "                print(f\"     Total iterations: {len(values)}\")\n",
    "\n",
    "        return loss_history\n",
    "\n",
    "# ================================================================\n",
    "# AVVIO DEL TRAINING CON CURRICULUM LEARNING\n",
    "# ================================================================\n",
    "\n",
    "# Sostituisci il loop di training originale con questo:\n",
    "loss_history = train_with_curriculum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3067ab8",
   "metadata": {},
   "source": [
    "## Small test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def visualize_reconstruction(models_dict, train_loader, device, num_samples=2, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualizza e confronta originale vs ricostruzione per alcuni campioni casuali.\n",
    "    \n",
    "    Args:\n",
    "        models_dict: dizionario con i modelli {'style_encoder': ..., 'content_encoder': ..., 'decoder': ...}\n",
    "        train_loader: DataLoader per il training\n",
    "        device: dispositivo (cuda/cpu)\n",
    "        num_samples: numero di campioni da visualizzare\n",
    "        save_path: path dove salvare le immagini (opzionale)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Estrai i modelli\n",
    "    style_encoder = models_dict['style_encoder']\n",
    "    content_encoder = models_dict['content_encoder']\n",
    "    decoder = models_dict['decoder']\n",
    "    \n",
    "    # Metti i modelli in modalità eval\n",
    "    style_encoder.eval()\n",
    "    content_encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    print(f\"🎯 Visualizing {num_samples} reconstruction examples...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Prendi un batch casuale\n",
    "        batch_iterator = iter(train_loader)\n",
    "        x, labels = next(batch_iterator)\n",
    "        \n",
    "        # Trasferisci su device\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        print(f\"📊 Batch shape: {x.shape}\")\n",
    "        print(f\"📋 Labels: {labels}\")\n",
    "        \n",
    "        # Limita al numero di campioni richiesto\n",
    "        x = x[:num_samples]\n",
    "        labels = labels[:num_samples]\n",
    "        \n",
    "        # Forward pass attraverso i modelli\n",
    "        print(\"🔄 Forward pass attraverso i modelli...\")\n",
    "        \n",
    "        # Encoding\n",
    "        style_emb, class_emb = style_encoder(x, labels)\n",
    "        content_emb = content_encoder(x)\n",
    "        \n",
    "        print(f\"   Style embedding shape: {style_emb.shape}\")\n",
    "        print(f\"   Class embedding shape: {class_emb.shape}\")\n",
    "        print(f\"   Content embedding shape: {content_emb.shape}\")\n",
    "        \n",
    "        # Estrai la parte STFT (prime 513 frequenze)\n",
    "        stft_original = x[:, :, :, :, :513]  # (batch, sections, channels, time, freq)\n",
    "        \n",
    "        # Ricostruzione\n",
    "        print(\"🔧 Generating reconstruction...\")\n",
    "        # duplicate class embedding from (2,d) to (B,d)\n",
    "        B = content_emb.size(0)\n",
    "        class_emb = class_emb.repeat(B, 1)\n",
    "        reconstructed = decoder(content_emb, class_emb, y=stft_original)\n",
    "        \n",
    "        print(f\"   Original STFT shape: {stft_original.shape}\")\n",
    "        print(f\"   Reconstructed shape: {reconstructed.shape}\")\n",
    "        \n",
    "        # Visualizza ogni campione\n",
    "        for i in range(num_samples):\n",
    "            print(f\"\\n📈 Visualizing sample {i+1}/{num_samples} (Label: {labels[i].item()})\")\n",
    "            \n",
    "            # Prendi una sezione casuale (es. la prima)\n",
    "            section_idx = 0\n",
    "            \n",
    "            original_section = stft_original[i, section_idx]  # (channels, time, freq)\n",
    "            reconstructed_section = reconstructed[i, section_idx]  # (channels, time, freq)\n",
    "            \n",
    "            print(f\"   Section {section_idx} - Original shape: {original_section.shape}\")\n",
    "            print(f\"   Section {section_idx} - Reconstructed shape: {reconstructed_section.shape}\")\n",
    "            \n",
    "            # Visualizza originale\n",
    "            print(f\"   📊 Original STFT - Sample {i+1}\")\n",
    "            plot_stft(original_section, log_scale=True)\n",
    "            \n",
    "            # Visualizza ricostruzione\n",
    "            print(f\"   🔧 Reconstructed STFT - Sample {i+1}\")\n",
    "            plot_stft(reconstructed_section, log_scale=True)\n",
    "            \n",
    "            # Calcola e visualizza la differenza\n",
    "            print(f\"   📉 Reconstruction Error - Sample {i+1}\")\n",
    "            plot_reconstruction_error(original_section, reconstructed_section)\n",
    "            \n",
    "            # Salva se richiesto\n",
    "            if save_path:\n",
    "                save_comparison_plots(original_section, reconstructed_section, \n",
    "                                    labels[i].item(), i, save_path)\n",
    "\n",
    "\n",
    "def plot_reconstruction_error(original, reconstructed, sr=22050, hop_length=256):\n",
    "    \"\"\"\n",
    "    Visualizza l'errore di ricostruzione.\n",
    "    \n",
    "    Args:\n",
    "        original: tensor originale (channels, time, freq)\n",
    "        reconstructed: tensor ricostruito (channels, time, freq)\n",
    "        sr: sample rate\n",
    "        hop_length: hop length per STFT\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calcola magnitude per entrambi\n",
    "    orig_real, orig_imag = original[0], original[1]\n",
    "    recon_real, recon_imag = reconstructed[0], reconstructed[1]\n",
    "    \n",
    "    orig_magnitude = torch.hypot(orig_real, orig_imag)\n",
    "    recon_magnitude = torch.hypot(recon_real, recon_imag)\n",
    "    \n",
    "    # Errore assoluto\n",
    "    error = torch.abs(orig_magnitude - recon_magnitude)\n",
    "    \n",
    "    # Errore relativo (in dB)\n",
    "    error_db = 20 * torch.log10(error + 1e-8)\n",
    "    \n",
    "    # Visualizza\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Subplot 1: Errore assoluto\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(\n",
    "        error.T.cpu().numpy(),\n",
    "        origin='lower',\n",
    "        aspect='auto',\n",
    "        extent=[0, original.shape[1] * hop_length / sr, 0, sr/2]\n",
    "    )\n",
    "    plt.colorbar(label='Absolute Error')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.title('Absolute Reconstruction Error')\n",
    "    \n",
    "    # Subplot 2: Errore in dB\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(\n",
    "        error_db.T.cpu().numpy(),\n",
    "        origin='lower',\n",
    "        aspect='auto',\n",
    "        extent=[0, original.shape[1] * hop_length / sr, 0, sr/2]\n",
    "    )\n",
    "    plt.colorbar(label='Error (dB)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.title('Reconstruction Error (dB)')\n",
    "    \n",
    "    # Subplot 3: Istogramma degli errori\n",
    "    plt.subplot(2, 2, 3)\n",
    "    error_flat = error.flatten().cpu().numpy()\n",
    "    plt.hist(error_flat, bins=50, alpha=0.7, color='red')\n",
    "    plt.xlabel('Absolute Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Error Distribution')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    # Subplot 4: Statistiche\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Calcola statistiche\n",
    "    mae = torch.mean(error).item()\n",
    "    mse = torch.mean(error**2).item()\n",
    "    rmse = torch.sqrt(torch.mean(error**2)).item()\n",
    "    max_error = torch.max(error).item()\n",
    "    \n",
    "    # Calcola SNR\n",
    "    signal_power = torch.mean(orig_magnitude**2)\n",
    "    noise_power = torch.mean(error**2)\n",
    "    snr_db = 10 * torch.log10(signal_power / noise_power).item()\n",
    "    \n",
    "    stats_text = f\"\"\"\n",
    "    Reconstruction Statistics:\n",
    "    \n",
    "    MAE: {mae:.6f}\n",
    "    MSE: {mse:.6f}\n",
    "    RMSE: {rmse:.6f}\n",
    "    Max Error: {max_error:.6f}\n",
    "    \n",
    "    SNR: {snr_db:.2f} dB\n",
    "    \n",
    "    Original Range: [{torch.min(orig_magnitude):.4f}, {torch.max(orig_magnitude):.4f}]\n",
    "    Reconstructed Range: [{torch.min(recon_magnitude):.4f}, {torch.max(recon_magnitude):.4f}]\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.text(0.1, 0.9, stats_text, transform=plt.gca().transAxes, \n",
    "             fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def save_comparison_plots(original, reconstructed, label, sample_idx, save_path):\n",
    "    \"\"\"\n",
    "    Salva i plot di confronto su file.\n",
    "    \n",
    "    Args:\n",
    "        original: tensor originale\n",
    "        reconstructed: tensor ricostruito\n",
    "        label: etichetta del campione\n",
    "        sample_idx: indice del campione\n",
    "        save_path: directory dove salvare\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # Calcola magnitudes\n",
    "    orig_real, orig_imag = original[0], original[1]\n",
    "    recon_real, recon_imag = reconstructed[0], reconstructed[1]\n",
    "    \n",
    "    orig_magnitude = torch.hypot(orig_real, orig_imag)\n",
    "    recon_magnitude = torch.hypot(recon_real, recon_imag)\n",
    "    \n",
    "    # Converti in dB\n",
    "    orig_db = 20 * torch.log10(orig_magnitude + 1e-8)\n",
    "    recon_db = 20 * torch.log10(recon_magnitude + 1e-8)\n",
    "    \n",
    "    # Crea figura comparativa\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Originale\n",
    "    im1 = axes[0].imshow(orig_db.T.cpu().numpy(), origin='lower', aspect='auto')\n",
    "    axes[0].set_title(f'Original (Label: {label})')\n",
    "    axes[0].set_xlabel('Time')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    plt.colorbar(im1, ax=axes[0], label='Magnitude (dB)')\n",
    "    \n",
    "    # Ricostruzione\n",
    "    im2 = axes[1].imshow(recon_db.T.cpu().numpy(), origin='lower', aspect='auto')\n",
    "    axes[1].set_title(f'Reconstructed (Label: {label})')\n",
    "    axes[1].set_xlabel('Time')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    plt.colorbar(im2, ax=axes[1], label='Magnitude (dB)')\n",
    "    \n",
    "    # Differenza\n",
    "    diff = torch.abs(orig_db - recon_db)\n",
    "    im3 = axes[2].imshow(diff.T.cpu().numpy(), origin='lower', aspect='auto')\n",
    "    axes[2].set_title(f'Absolute Difference (Label: {label})')\n",
    "    axes[2].set_xlabel('Time')\n",
    "    axes[2].set_ylabel('Frequency')\n",
    "    plt.colorbar(im3, ax=axes[2], label='|Difference| (dB)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    filename = f'reconstruction_comparison_sample_{sample_idx}_label_{label}.png'\n",
    "    filepath = os.path.join(save_path, filename)\n",
    "    plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"   💾 Saved comparison plot: {filepath}\")\n",
    "\n",
    "\n",
    "def audio_reconstruction_test(models_dict, train_loader, device, num_samples=1):\n",
    "    \"\"\"\n",
    "    Test completo che include anche la ricostruzione audio.\n",
    "    \n",
    "    Args:\n",
    "        models_dict: dizionario con i modelli\n",
    "        train_loader: DataLoader\n",
    "        device: dispositivo\n",
    "        num_samples: numero di campioni da testare\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🎵 Testing audio reconstruction pipeline...\")\n",
    "    \n",
    "    # Visualizza ricostruzioni spettrali\n",
    "    visualize_reconstruction(models_dict, train_loader, device, num_samples)\n",
    "    \n",
    "    # Test ricostruzione audio (se hai le funzioni inverse)\n",
    "    print(\"\\n🔊 Testing audio reconstruction...\")\n",
    "    \n",
    "    style_encoder = models_dict['style_encoder']\n",
    "    content_encoder = models_dict['content_encoder']\n",
    "    decoder = models_dict['decoder']\n",
    "    \n",
    "    style_encoder.eval()\n",
    "    content_encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_iterator = iter(train_loader)\n",
    "        x, labels = next(batch_iterator)\n",
    "        \n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Prendi un campione\n",
    "        sample = x[0:1]  # (1, sections, channels, time, freq)\n",
    "        sample_label = labels[0:1]\n",
    "        \n",
    "        # Forward pass\n",
    "        style_emb, class_emb = style_encoder(sample, sample_label)\n",
    "        content_emb = content_encoder(sample)\n",
    "        \n",
    "        # Ricostruzione\n",
    "        stft_original = sample[:, :, :, :, :513]\n",
    "\n",
    "        # duplicate class embedding from (2,d) to (B,d)\n",
    "        B = content_emb.size(0)\n",
    "        class_emb = class_emb.repeat_interleave(repeats=B//2, dim=0)\n",
    "        reconstructed = decoder(content_emb, class_emb, y=stft_original)\n",
    "        \n",
    "        print(f\"🎯 Audio reconstruction test completed!\")\n",
    "        print(f\"   Original shape: {stft_original.shape}\")\n",
    "        print(f\"   Reconstructed shape: {reconstructed.shape}\")\n",
    "        \n",
    "        # Qui potresti aggiungere la ricostruzione audio vera e propria\n",
    "        # usando le tue funzioni inverse_STFT e sections2spectrogram\n",
    "        \n",
    "        return {\n",
    "            'original': stft_original,\n",
    "            'reconstructed': reconstructed,\n",
    "            'style_emb': style_emb,\n",
    "            'content_emb': content_emb,\n",
    "            'label': sample_label\n",
    "        }\n",
    "\n",
    "\n",
    "# Esempio di utilizzo:\n",
    "\"\"\"\n",
    "# Dopo aver caricato i modelli\n",
    "models_dict = {\n",
    "    'style_encoder': style_encoder,\n",
    "    'content_encoder': content_encoder,\n",
    "    'decoder': decoder\n",
    "}\n",
    "\n",
    "# Visualizza ricostruzioni\n",
    "visualize_reconstruction(models_dict, train_loader, device, num_samples=3)\n",
    "\n",
    "# Test completo con salvataggio\n",
    "visualize_reconstruction(models_dict, train_loader, device, \n",
    "                        num_samples=2, save_path=\"reconstruction_results\")\n",
    "\n",
    "# Test audio completo\n",
    "results = audio_reconstruction_test(models_dict, train_loader, device)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    'style_encoder': style_encoder,\n",
    "    'content_encoder': content_encoder,\n",
    "    'decoder': decoder\n",
    "}\n",
    "\n",
    "train_loader = get_dataloader(\n",
    "        piano_dir=config[\"piano_dir\"],\n",
    "        violin_dir=config[\"violin_dir\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        stats_path=config[\"stats_path\"]\n",
    "    )\n",
    "\n",
    "# Visualizza 3 campioni casuali\n",
    "visualize_reconstruction(models_dict, train_loader, device, num_samples=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca248eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
